{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af19e85e",
   "metadata": {},
   "source": [
    "# Structure MCMC with DEO parallel tempering scheme (and dynamic tuning of temperatures)\n",
    "### $MC^3$, $REV$ and $MBR$ moves implemented\n",
    "In this notebook you can find the functions for sampling DAGs using a simple structure MCMC or using a structure MCMC with a parallel tempering scheme implemented (DEO, SEO and single swap schemes).\n",
    "\n",
    "Two structure priors implemented: uniform and sparse.\n",
    "\n",
    "\n",
    "A practical example of sampling DAGs using DEO Structure MCMC can be found at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ec1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import splines   \n",
    "from scipy.special import logsumexp\n",
    "from math import comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf47a6",
   "metadata": {
    "hideCode": false,
    "id": "8dcf47a6"
   },
   "source": [
    "### Loading the score file for the data  from .jkl format (BDeu or BGe score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684d8f74",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "684d8f74",
    "outputId": "3573ac84-dc6e-45a2-d913-892aa3a8627a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def cache_f (path,max_parents,n_nodes):\n",
    "\n",
    "    with open(path,'r') as file:\n",
    "        filedata = file.readlines()\n",
    "\n",
    "    n_parents_set=[]\n",
    "    cache ={}\n",
    "    \n",
    "    t=1\n",
    "    vertices=[]\n",
    "    for i in range (n_nodes):\n",
    "        line = filedata[t]\n",
    "        vertices.append(int(re.findall(r'\\d+', line)[0]))\n",
    "        t+=int(re.findall(r'\\d+', line)[1])+1\n",
    "\n",
    "    t=1\n",
    "    for i in vertices :\n",
    "        line = filedata[t]\n",
    "        now_n_parents_set =int(re.findall(r'\\d+', line)[1])\n",
    "\n",
    "        n_parents_set.append(now_n_parents_set)\n",
    "        now_dict= {}\n",
    "\n",
    "        for j in range(now_n_parents_set):\n",
    "            now_parents=()\n",
    "            for k in range (len(re.findall(r'\\d+', filedata[t+j+1]))-3):\n",
    "\n",
    "                now_parents= now_parents + (int(re.findall(r'\\d+', filedata[t+j+1])[k+3]),)\n",
    "\n",
    "            now_parents=tuple(sorted(now_parents))\n",
    "\n",
    "            now_dict[now_parents]=float(filedata[t+j+1].split(' ')[0])\n",
    "        cache[i]=now_dict\n",
    "        t=t+now_n_parents_set+1\n",
    "    return cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a3f48",
   "metadata": {
    "hideCode": false,
    "id": "483a3f48"
   },
   "source": [
    "### Generic functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481a610d",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "481a610d",
    "outputId": "a7a1cd98-3494-4d2e-9af7-d444b081e8e9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_dag(adjacency_matrix):\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "\n",
    "    colors = np.zeros(num_nodes, dtype=int)\n",
    "\n",
    "    def dfs(node):\n",
    "        nonlocal colors\n",
    "\n",
    "        colors[node] = 1  \n",
    "\n",
    "        for neighbor in np.where(adjacency_matrix[node] == 1)[0]:\n",
    "            if colors[neighbor] == 1:\n",
    "                return False  \n",
    "            elif colors[neighbor] == 0:\n",
    "                if not dfs(neighbor):\n",
    "                    return False\n",
    "\n",
    "        colors[node] = 2 \n",
    "        return True\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        if colors[node] == 0:\n",
    "            if not dfs(node):\n",
    "                return False  \n",
    "\n",
    "    return True \n",
    "\n",
    "def generate_random_dag_adjacency_matrix(num_nodes,max_parents):\n",
    "    if num_nodes <= 0:\n",
    "        raise ValueError(\"Number of nodes must be greater than 0.\")\n",
    "\n",
    "    nodes = np.random.permutation(num_nodes)\n",
    "\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "\n",
    "    for i in range(num_nodes - 1):\n",
    "        num_edges = np.random.randint(1, num_nodes - i)\n",
    "\n",
    "        target_nodes = np.random.choice(nodes[i+1:], size=num_edges, replace=False)\n",
    "\n",
    "        adjacency_matrix[nodes[i], target_nodes] = 1\n",
    "\n",
    "    new_dag= np.zeros((num_nodes,num_nodes),dtype=np.int8)\n",
    "    for i in range (num_nodes):\n",
    "        a=list(np.where(adjacency_matrix[:,i]==1)[0])\n",
    "        b=random.randint(0,max_parents)\n",
    "        c=random.sample(sorted(a), min(len(a),b))\n",
    "        for j in c:\n",
    "            new_dag[j,i]=1\n",
    "    return new_dag\n",
    "\n",
    "\n",
    "def score(dag):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "\n",
    "\n",
    "def bisection_at_x (f,a,b,x,max_iter=100,tol=1e-6):\n",
    "    for i in range (max_iter):\n",
    "        c = (a + b) / 2\n",
    "        if ((f(c) == x) or ((b - a) / 2 < tol)):\n",
    "            return(c)\n",
    "        if (f(c)< x):\n",
    "            a = c\n",
    "        else:\n",
    "            b = c\n",
    "    return (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1fe73",
   "metadata": {},
   "source": [
    "### Single $MC^3$ move (for structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c063b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mcmcmc (dag_now_p, loglik_now_p, prior_now_p, score_now_p,cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, max_parents,uniform\n",
    "\n",
    "    if beta==None:\n",
    "        beta=1\n",
    "    \n",
    "    dag0=np.copy(dag_now_p)\n",
    "    \n",
    "    condition=False\n",
    "    n_variables=len(dag_now_p[0])\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dag_now_p)\n",
    "        if (dag_now_p[u,v]==1) :\n",
    "            dag1[u,v]=0\n",
    "        elif (dag_now_p[v,u]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if (np.sum(dag_now_p[:,v])>=max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dag_now_p[u,v]==0 and dag_now_p[v,u]==0):\n",
    "            dag1[u,v]=1\n",
    "            if np.sum(dag_now_p[:,v])>=max_parents:\n",
    "                dag1[u,v]=0\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "    prior_0=np.copy(prior_now_p)\n",
    "    loglik_0=np.copy(loglik_now_p)\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/comb((n_variables-1),np.sum(dag1[:,i])))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "\n",
    "    prior_1=np.log(prior_1)\n",
    "\n",
    "    \n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "\n",
    "        dag_now=np.copy(dag1)\n",
    "        prior_now = np.copy(prior_1)\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now= np.copy(prior_now+loglik_now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fb405",
   "metadata": {},
   "source": [
    "### Single $MC^3$ move (for PT Structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f06a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def pt_mcmcmc (dags_now_p, loglik_now_p, prior_now_p, beta,cache):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition=False\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "        if (dags_now_p[u,v,iterator]==1) :\n",
    "            dag1[u,v]=0\n",
    "\n",
    "        elif (dags_now_p[v,u,iterator]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if  (np.sum(dags_now_p[:,v,iterator])>=max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "      \n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dags_now_p[u,v,iterator]==0 and dags_now_p[v,u,iterator]==0):\n",
    "            dag1[u,v]=1\n",
    "            if  np.sum(dags_now_p[:,v,iterator])>=max_parents:\n",
    "                dag1[u,v]=0\n",
    "\n",
    "            if (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "    prior_0=np.copy(prior_now_p[iterator])\n",
    "    loglik_0=np.copy(loglik_now_p[iterator])\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag1[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "\n",
    "    prior_1=np.log(prior_1)\n",
    "\n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "\n",
    "        dags_now[:,:,iterator]=np.copy(dag1)\n",
    "        prior_now[iterator] = np.copy(prior_1)\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90bf5c1",
   "metadata": {},
   "source": [
    "### Single $REV$ move (for Structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9742c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def rev (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    " \n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "  \n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "     \n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "           \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "            \n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "     \n",
    "                dd_u=list(set(dd_u))\n",
    "    \n",
    "        d_u=set(d_u)\n",
    " \n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    " \n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "         \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "      \n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v=set(d_v)\n",
    "\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "            \n",
    "\n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i])\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "\n",
    "        \n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "\n",
    "        \n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            if uniform==False:\n",
    "                z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_j_cross.append(cache[v][i])\n",
    "                \n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "\n",
    "            \n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "            \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[v][i])\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    " \n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    " \n",
    "        d_u_plus=set(d_u_plus)\n",
    " \n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    " \n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            if uniform==False:\n",
    "                z_i_cross.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_i_cross.append(cache[u][i])\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        dag_now=np.copy(dag_tilde)\n",
    "        prior_now = np.copy(np.log(prior_1))\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=np.copy(loglik_now+prior_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211de3f5",
   "metadata": {},
   "source": [
    "### Single $REV$ move (for PT structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bf29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_rev (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    "    \n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "\n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "  \n",
    "\n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "  \n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "    \n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "      \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "                  \n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "     \n",
    "                dd_u=list(set(dd_u))\n",
    "      \n",
    "        d_u=set(d_u)\n",
    "  \n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    "  \n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "       \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "           \n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "      \n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v=set(d_v)\n",
    "\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "    \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta)\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    " \n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "\n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            if uniform==False:\n",
    "                z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_j_cross.append(cache[v][i]*beta)\n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "\n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[v][i]*beta)\n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u_plus=set(d_u_plus)\n",
    "\n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    "\n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            if uniform==False:\n",
    "                z_i_cross.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_i_cross.append(cache[u][i]*beta)\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        prior_1=1\n",
    "        loglik_1=0\n",
    "\n",
    "\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "            loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "        \n",
    "        dags_now[:,:,iterator]=np.copy(dag_tilde)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ef235",
   "metadata": {},
   "source": [
    "### Single $MBR$ move (for structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d36c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbr (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        \n",
    "        u=random.randint(0,n_variables-1)\n",
    " \n",
    "        \n",
    "        pi_i=np.where(dag0[:,u]==1)[0]\n",
    "\n",
    "        \n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u=np.where(dag1[u,:]==1)[0]        \n",
    "        for i in c_u:\n",
    "            dag1[:,i]=np.zeros(n_variables)\n",
    "            dag1[u,i]=1\n",
    "        \n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u=set(d_u)\n",
    "\n",
    "        pi_i_set2=[item for item in cache[u]]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]\n",
    "\n",
    "        pi_i_set=pi_i_set2.copy()\n",
    "\n",
    "        for i in pi_i:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "\n",
    "        \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i])\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        \n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "        \n",
    "        ''' until here the new parents set of u is sampled'''\n",
    "        z_c=0\n",
    "        c_u=list(c_u)\n",
    "\n",
    "        random.shuffle(c_u)\n",
    "        c_u=tuple(c_u)\n",
    "\n",
    "        for v in c_u:\n",
    "\n",
    "            d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "                \n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i])\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c+=z_j_cross\n",
    "\n",
    "            \n",
    "            \n",
    "            log_probs = Z\n",
    "            num_categories = len(Z)\n",
    "            gumbels = np.random.gumbel(size=num_categories)\n",
    "            sample = np.argmax(log_probs + gumbels)\n",
    "            pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "            for i in pi_j_tilde:\n",
    "                dag_cross[i,v]=1\n",
    "\n",
    "        ''' backwards'''  \n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        dag_tilde[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u_b=np.where(dag_tilde[u,:]==1)[0]        \n",
    "        for i in c_u_b:\n",
    "            dag_tilde[:,i]=np.zeros(n_variables)\n",
    "            dag_tilde[u,i]=1\n",
    "\n",
    "        for i in pi_i_tilde:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]   \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_i_set2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[u][i])\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        for i in pi_i:\n",
    "            dag_tilde[i,u]=1\n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "        z_c_b=0\n",
    "        c_u_b=list(c_u_b)\n",
    "\n",
    "        random.shuffle(c_u_b)\n",
    "        c_u_b=tuple(c_u_b)\n",
    "        for v in c_u_b:\n",
    "            d_v_plus=np.where(dag_tilde[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "  \n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_tilde[child,:]==1)[0]:\n",
    "          \n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "        \n",
    "                    dd_v=list(set(dd_v))\n",
    "    \n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i])\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c_b+=np.copy(z_j_cross)\n",
    "\n",
    "            dag_tilde[:,v]=np.copy(dag0[:,v])\n",
    "    \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_cross[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_cross[:,i]==1)[0])]\n",
    "\n",
    "    alpha=min(0,z_star_i_dot_j+z_c-z_star_j_dot_i-z_c_b)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        dag_now=np.copy(dag_cross)\n",
    "        prior_now = np.copy(np.log(prior_1))\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=np.copy(loglik_now+prior_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d5cbe",
   "metadata": {},
   "source": [
    "### Single $MBR$ move (for PT structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ca62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_mbr (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        \n",
    "        u=random.randint(0,n_variables-1)\n",
    "\n",
    "        \n",
    "        pi_i=np.where(dag0[:,u]==1)[0]\n",
    "\n",
    "        \n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u=np.where(dag1[u,:]==1)[0]        \n",
    "        for i in c_u:\n",
    "            dag1[:,i]=np.zeros(n_variables)\n",
    "            dag1[u,i]=1\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u=set(d_u)\n",
    "\n",
    "        pi_i_set2=[item for item in cache[u]]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]\n",
    "\n",
    "        pi_i_set=pi_i_set2.copy()\n",
    "\n",
    "        for i in pi_i:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "\n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta)\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        \n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "        \n",
    "        ''' until here the new parents set of u is sampled'''\n",
    "        z_c=0\n",
    "        c_u=list(c_u)\n",
    "\n",
    "        random.shuffle(c_u)\n",
    "        c_u=tuple(c_u)\n",
    "\n",
    "        for v in c_u:\n",
    "\n",
    "            d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "            \n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i]*beta)\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c+=z_j_cross\n",
    "\n",
    "            \n",
    "            log_probs = Z\n",
    "            num_categories = len(Z)\n",
    "            gumbels = np.random.gumbel(size=num_categories)\n",
    "            sample = np.argmax(log_probs + gumbels)\n",
    "            pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "            for i in pi_j_tilde:\n",
    "                dag_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        ''' backwards'''  \n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        dag_tilde[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u_b=np.where(dag_tilde[u,:]==1)[0]        \n",
    "        for i in c_u_b:\n",
    "            dag_tilde[:,i]=np.zeros(n_variables)\n",
    "            dag_tilde[u,i]=1\n",
    "        \n",
    "\n",
    "        for i in pi_i_tilde:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]   \n",
    "            \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_i_set2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[u][i]*beta)\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        for i in pi_i:\n",
    "            dag_tilde[i,u]=1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        z_c_b=0\n",
    "        c_u_b=list(c_u_b)\n",
    "\n",
    "        random.shuffle(c_u_b)\n",
    "        c_u_b=tuple(c_u_b)\n",
    "        for v in c_u_b:\n",
    "            d_v_plus=np.where(dag_tilde[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    " \n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_tilde[child,:]==1)[0]:\n",
    "   \n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i]*beta)\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c_b+=np.copy(z_j_cross)\n",
    "\n",
    "            dag_tilde[:,v]=np.copy(dag0[:,v])\n",
    "    \n",
    "\n",
    "        condition= True\n",
    "    \n",
    "\n",
    "    \n",
    "    alpha=min(0,z_star_i_dot_j+z_c-z_star_j_dot_i-z_c_b)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        prior_1=1\n",
    "        loglik_1=0\n",
    "\n",
    "\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_cross[:,i]))))\n",
    "            loglik_1+= cache[i][tuple(np.where(dag_cross[:,i]==1)[0])]\n",
    "        \n",
    "        dags_now[:,:,iterator]=np.copy(dag_cross)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8e087",
   "metadata": {},
   "source": [
    "### Structure MCMC without PT (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d83fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, prob_rev=.7, prob_mbr=.2,seed=None,uniform_p=False):\n",
    "    global score_now,n_variables, dag_now, loglik_now, prior_now, tot_swaps, max_parents,uniform\n",
    "\n",
    "    uniform=uniform_p\n",
    "    n_variables=int(n_variables_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    dag_now= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    dags =np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    scores=np.zeros(n_iter)\n",
    "\n",
    "    prior_now=1\n",
    "    loglik_now=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_now= prior_now*(1/comb((n_variables-1),np.sum(dag_now[:,i])))\n",
    "        loglik_now+= cache[i][tuple(np.where(dag_now[:,i]==1)[0])]\n",
    "    \n",
    "    prior_now=np.log(prior_now)\n",
    "    score_now=loglik_now+prior_now\n",
    "\n",
    "    dags[:,:,0]=dag_now\n",
    "    scores[0]=score_now\n",
    "    for i in range(n_iter-1):\n",
    "        r_num=random.random() \n",
    "        if r_num> prob_rev+prob_mbr:\n",
    "            mcmcmc(dag_now, loglik_now, prior_now, score_now, cache,1)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "        elif r_num<prob_rev:\n",
    "\n",
    "            rev(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "        else:\n",
    "\n",
    "            mbr(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "    return scores,dags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa380a6c",
   "metadata": {},
   "source": [
    "### DEO structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca0b6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            \n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "      \n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "            if complete==True:\n",
    "                beta_array_train.append(list(betas))\n",
    "            \n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "        \n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "     \n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "\n",
    "                if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "\n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r[1:],R[1:],betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f8276",
   "metadata": {},
   "source": [
    "### Random single swap structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac37c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "        \n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            \n",
    "            index=random.randint(0,n_chains-1)\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if j==index:\n",
    "\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "\n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "            if complete==True:\n",
    "                beta_array_train.append(list(betas))\n",
    "            \n",
    "\n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "\n",
    "        index=random.randint(0,n_chains-1)\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "                if j==index:\n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r[1:],R[1:],betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaab703",
   "metadata": {},
   "source": [
    "### SEO structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11dbc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            K=random.random()\n",
    "            if K<.5:\n",
    "                K=1\n",
    "            else:\n",
    "                K=2\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "                #print(alpha,j)\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "                        #print('swap',j)\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "        if complete==True:\n",
    "            beta_array_train.append(list(betas))\n",
    "            \n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        K=random.random()\n",
    "        if K<.5:\n",
    "            K=1\n",
    "        else:\n",
    "            K=2\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "\n",
    "                if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "          \n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r[1:],R[1:],betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5e196",
   "metadata": {},
   "source": [
    "### Diagnostic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef8f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restarts(chain):\n",
    "    rest=0\n",
    "    ground=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        ground[int(chain[2][0,i])]=1\n",
    "        if ground[int(chain[2][chain[3]-1,i])]==1:\n",
    "            ground[int(chain[2][chain[3]-1,i])]=0\n",
    "            rest+=1\n",
    "    return rest\n",
    "\n",
    "def plot_swaps (chain):\n",
    "    a=[]\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        a.append(int(np.where(chain[2][:,i]==2)[0]))\n",
    "    plt.plot(a)\n",
    "    plt.show()\n",
    "\n",
    "def score(dag,cache):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "    n_variables=len(dag)\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "def mixing_ratio(chain):\n",
    "    ratio_post=0\n",
    "    ratio=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        for j in range(chain[3]):\n",
    "            ratio[int(chain[2][j,i])]+=(chain[3]-1-j)/(chain[3])\n",
    "        ratio_post+= ratio[int(chain[2][chain[3]-1,i])]\n",
    "        ratio[int(chain[2][chain[3]-1,i])]=0\n",
    "    return ratio_post/len(chain[2][0,:])\n",
    "\n",
    "def dag_mean_post (x,start,end):\n",
    "    dim=len(x[:,0,0])\n",
    "    dag=np.zeros((dim,dim))\n",
    "    for i in range(start,end):\n",
    "        dag += x[:,:,i]\n",
    "    return dag/(end-start) \n",
    "\n",
    "def l1_loss(x,c,ref):\n",
    "    \n",
    "    dmp=[]\n",
    "    for i in x:\n",
    "        dmp.append(dag_mean_post(c[1],x[0],i))\n",
    "\n",
    "    u=[]\n",
    "    for i in dmp:\n",
    "        u.append(np.sum(np.abs(i-ref)))\n",
    "    return u\n",
    "\n",
    "def max_loss(x,c,ref):\n",
    "    \n",
    "    dmp=[]\n",
    "    for i in x:\n",
    "        dmp.append(dag_mean_post(c[1],x[0],i))\n",
    "\n",
    "    u=[]\n",
    "    for i in dmp:\n",
    "        u.append(np.max(np.abs(i-ref)))\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1c33a",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4a8223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5990629  0.5190942  0.49718055 0.49537916 0.49149982 0.4865013\n",
      " 0.48333452 0.48420506 0.49411461 0.51801748 0.48053886 0.51560516] rejection ratio among chains\n",
      "[0.00000000e+00 6.07490540e-04 1.33419037e-03 2.71511078e-03\n",
      " 5.30910492e-03 9.13906097e-03 1.74932480e-02 4.51250076e-02\n",
      " 1.11445427e-01 2.16715813e-01 3.63078117e-01 5.90474129e-01\n",
      " 1.00000000e+00] betas\n"
     ]
    }
   ],
   "source": [
    "ASIA_cache=cache_f('data/asia-10000-3p.jkl',3,8)\n",
    "\n",
    "ASIA_structure_MCMC=deo_structure_mcmc (n_variables_p=8, max_parents_p=3, n_iter=50000, cache=ASIA_cache, training_iter=2000, n_chains_p=30, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f655d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAHFCAYAAADBtOziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRrUlEQVR4nO3dd3xUVf7/8fckmUxCQgIkQEgIBLAAKqLBElw3sEpZXMVKU4SvgN+orBTdRVCWolIEsfBzwQJYV5FFUFzUAAKrki+CBakiJbQYqiS01Dm/P8JcGCaJKZMZEl7Px2OUuffMveeeucn55HPPPddmjDECAACAVwX4uwIAAAA1EUEWAABAFSDIAgAAqAIEWQAAAFWAIAsAAKAKEGQBAABUAYIsAACAKkCQBQAAUAUIsgAAAKoAQRZQjNWrV+uOO+5QkyZN5HA41LBhQyUlJemxxx7zd9XKbfHixRo7dqy/q+F1HTp0UIcOHSr02QkTJmjhwoXl/tyhQ4fkcDhks9m0du3aYssYY/TBBx/oxhtvVIMGDRQSEqLGjRurS5cueuONN9zK2mw2DR48uNjtrF+/XjabTXa7Xb/++mu563qu/v37KyEhodLb8dV2y6JDhw66/PLL/bLvilixYoVsNptWrFjh76rARwiygHP85z//Ufv27ZWdna3nnntOqampeumll3TDDTdo7ty5/q5euS1evFjjxo3zdzXOKxUNst555x3l5eVJkmbNmlVsmZEjR6p3795q1aqV3njjDX322Wd65pln1LBhQ3388cdl3pcrICsoKNDbb79d7rr6yujRo7VgwQJ/V6NauPrqq5WWlqarr77a31WBjwT5uwLA+ea5555Ts2bN9MUXXygo6MyPSK9evfTcc8/5tC4nT55UrVq1fLY/Y4xycnIUGhrqs31WJ7Nnz1aDBg3UtGlTvf/++5o2bZpbW506dUovvvii7r//fr322mtun+3fv7+cTmeZ9pObm6v33ntPV155pQ4dOqTZs2drxIgRXj2WynKdmy1atPB3Vaqct34OIyIidP3113uhRqguyGQB5zh8+LCio6PdAiyXgADPH5l//etfSkpKUnh4uMLDw9W2bVuPLMfs2bN15ZVXKiQkRPXq1dMdd9yhzZs3u5Xp37+/wsPDtX79enXu3Fm1a9fWTTfdJEnKy8vTM888o5YtW8rhcKh+/fr6n//5Hx08eLDUY+nfv79eeeUVSUWXplyv9PR0a9ngwYM1c+ZMtWrVSg6HQ2+99ZYkady4cbruuutUr149RURE6Oqrr9asWbNU3DPly9IGS5cu1U033aSIiAjVqlVLN9xwg5YtW+ZWZuzYsbLZbPrhhx905513KiIiQpGRkbrvvvt+91gl6ciRI3r44YcVFxen4OBgNW/eXE8++aRyc3OtMjabTSdOnNBbb71ltUdZLjuuXr1aGzZsUN++fTVo0CBlZWVp/vz5bmVOnDih3NxcNWrUqNhtFHf+FGfhwoU6fPiwBg4cqH79+mnr1q36+uuvy/RZSXrzzTd16aWXyuFwqFWrVsVmwkq6dJWeni6bzaY333zTWlbauVnc5ULXefXOO++oVatWqlWrlq688kp9+umnHvX4+OOP1aZNGzkcDjVv3lwvvfSSdR6U1VdffaXrr79eoaGhiouL0+jRo1VYWOj1Yy3PcRWnuHq49rdt2zZ169ZN4eHhio+P12OPPeZ23qKaMgDcDBw40Egyf/3rX83//d//mby8vBLLjh492kgyd955p5k3b55JTU0106ZNM6NHj7bKTJgwwUgyvXv3Nv/5z3/M22+/bZo3b24iIyPN1q1brXL9+vUzdrvdJCQkmIkTJ5ply5aZL774whQWFpquXbuasLAwM27cOLNkyRLzxhtvmLi4ONO6dWtz8uTJEuu3bds2c/fddxtJJi0tzXrl5OQYY4yRZOLi4kybNm3Mv/71L/Pll1+aDRs2GGOM6d+/v5k1a5ZZsmSJWbJkiXn66adNaGioGTduXLnb4J133jE2m83cfvvt5qOPPjKLFi0yf/nLX0xgYKBZunSpVW7MmDFGkmnatKn529/+Zr744gszbdo0ExYWZq666iq37yI5OdkkJydb70+dOmXatGljwsLCzNSpU01qaqoZPXq0CQoKMt26dbPKpaWlmdDQUNOtWzerPTZu3FhiG7oMGjTISDIbN2402dnZplatWqZDhw4e5S666CJTu3Zt8/zzz5vNmzcbp9NZ4jYlmUceecRjeadOnYzD4TBHjhwx27ZtMzabzfTv3/9362iMMXPmzDGSTPfu3c2iRYvMu+++ay666CITHx9vmjZtapVbvny5kWSWL1/u9vmdO3caSWbOnDnWspLOTde6s7frOq6EhARz7bXXmg8//NAsXrzYdOjQwQQFBZnt27db5T777DMTEBBgOnToYBYsWGDmzZtnrrvuOpOQkGDK0j0lJyebqKgoExsba15++WXzxRdfmEcffdSjXb11rGU9rpIUV49+/fqZ4OBg06pVKzN16lSzdOlS849//MPYbDaPnzVUPwRZwDkOHTpk/vCHPxhJRpKx2+2mffv2ZuLEiebYsWNWuR07dpjAwEBz7733lrit3377zerQz7Z7927jcDhMnz59rGX9+vUzkszs2bPdyr7//vtGkpk/f77b8jVr1hhJ5p///Gepx/PII4+U2GFJMpGRkebIkSOlbqOwsNDk5+eb8ePHm6ioKCtwKEsbnDhxwtSrV8/ceuutHtu88sorzbXXXmstcwVZw4YNcyv73nvvGUnm3XfftZadG2TNnDnTSDIffvih22cnT55sJJnU1FRrWVhYmOnXr1+px3zuMURERJjrr7/eWtavXz9js9nMtm3b3Mp+++23pkmTJtb5U7t2bfOXv/zFvP322x4BV3FBVnp6ugkICDC9evVyO9awsDCTnZ1daj0LCwtNbGysufrqq932lZ6ebux2e6WCrOLOTde64oKshg0butU3MzPTBAQEmIkTJ1rLrrnmGhMfH29yc3OtZceOHTNRUVFlDrIkmY8//tht+aBBg0xAQIDZtWuXV4+1rMdVkpKCrOLO227duplLL730d7eJ8xuXC4FzREVF6auvvtKaNWs0adIkde/eXVu3btXIkSN1xRVX6NChQ5KkJUuWqLCwUI888kiJ20pLS9OpU6fUv39/t+Xx8fH605/+5HG5TJLuuusut/effvqp6tSpo1tvvVUFBQXWq23btoqJian0nUp/+tOfVLduXY/lX375pW6++WZFRkYqMDBQdrtd//jHP3T48GEdOHBAUtnaYNWqVTpy5Ij69evnVn+n06muXbtqzZo1OnHihNtn7r33Xrf3PXr0UFBQkJYvX17ifr788kuFhYXp7rvvdlvuavvi2rqsPvzwQ2VnZ+uBBx6wlj3wwAMyxmjOnDluZa+55hpt27ZNn3/+uUaNGqWkpCQtW7ZM999/v2677bZiL7eebc6cOXI6nR77OnHixO/eePHzzz8rIyNDffr0cbvc1rRpU7Vv3748h1ysc8/N0nTs2FG1a9e23jds2FANGjTQrl27JBVdWl27dq1uv/12BQcHW+XCw8N16623lnk/tWvX1m233ea2rE+fPnI6nfrvf/9b5u2cq6Rj/b3jkuR2nhcUFPzud26z2TyOuU2bNm7bRPVEkAWUoF27dhoxYoTmzZunjIwMDRs2TOnp6dbgd9cYocaNG5e4jcOHD0tSsWN0YmNjrfUutWrVUkREhNuy/fv36+jRowoODpbdbnd7ZWZmWkFfRRVXt2+//VadO3eWJL3++uv65ptvtGbNGj355JOSigZ4S2Vrg/3790uS7r77bo/6T548WcYYHTlyxO0zMTExbu+DgoIUFRXl0V5nO3z4sGJiYjzG8jRo0EBBQUGlfvb3zJo1SyEhIeratauOHj2qo0ePqk2bNkpISNCbb77pNv5Hkux2u7p06aJnn31WX3zxhfbs2aMOHTro008/1WeffVbifpxOp958803FxsYqMTHR2tfNN9+ssLCwEu9oPLsNJM/2K2lZeRR3bpYmKirKY5nD4bDOnd9++03GGDVs2NCjXHHLSlJcWdexVvQ7L+1Yf++40tPTPc7zlStX/u7+QkJCPLaZk5NTofrj/MHdhUAZ2O12jRkzRi+88II2bNggSapfv74kae/evYqPjy/2c65fyMXNc5SRkaHo6Gi3ZcUN9o2OjlZUVJQ+//zzYvdx9l/VFVHcPj/44APZ7XZ9+umnbr/8z532oCxt4DrG6dOnl3hn1bkdZWZmpuLi4qz3BQUFOnz4cLEdnEtUVJRWr14tY4zbMR04cEAFBQUebV1WZw86b9KkSbFlvvjiC3Xr1q3Uug0dOlQrVqzQhg0bSiy7dOlSK3tR3LH+3//9nzZt2qTWrVuXuB+pqP3Ode4y1/d67uDqkoL28gxEL4u6devKZrNZQfjZiqt/SUr7vKs9fHmssbGxWrNmjduySy+9tMLbQ/VGJgs4R0kTP7ruBoyNjZUkde7cWYGBgZoxY0aJ20pKSlJoaKjeffddt+V79+7Vl19+ad21VJq//OUvOnz4sAoLC9WuXTuP1+/9Anc4HJLOZJ/KwmazKSgoSIGBgdayU6dO6Z133nErV5Y2uOGGG1SnTh1t2rSp2Pq3a9fO7XKRJL333ntu7z/88EMVFBSUehfgTTfdpOPHj3sEgq47685u67MzD7/HlT16/fXXtXz5crfX4sWLZbfbNXv2bElSfn5+idmTc8+fkvYVEBCghQsXeuzL1faufRXn0ksvVaNGjfT++++7XaLatWuXVq1a5VbWdUfgTz/95Lb8k08+KXH73hQWFqZ27dpp4cKF1txjknT8+PEy360nSceOHfOo87/+9S8FBAToj3/8oyTfHmtwcLDH+V3ZP4RQfZHJAs7RpUsXNW7cWLfeeqtatmwpp9OpH3/8Uc8//7zCw8M1ZMgQSUW/uEeNGqWnn35ap06dUu/evRUZGalNmzbp0KFDGjdunOrUqaPRo0dr1KhRuv/++9W7d28dPnxY48aNU0hIiMaMGfO79enVq5fee+89devWTUOGDNG1114ru92uvXv3avny5erevbvuuOOOEj9/xRVXSJImT56sP//5zwoMDFSbNm08Apuz3XLLLZo2bZr69OmjBx98UIcPH9bUqVOtgM2lLG0QHh6u6dOnq1+/fjpy5IjuvvtuNWjQQAcPHtS6det08OBBjyDto48+UlBQkDp16qSNGzdq9OjRuvLKK9WjR48S63z//ffrlVdeUb9+/ZSenq4rrrhCX3/9tSZMmKBu3brp5ptvdmuTFStWaNGiRWrUqJFq165dbLDqmgi0VatWGjhwYLH7vfXWW/XJJ5/o4MGDstlsSkhI0D333KObb75Z8fHxOn78uFasWKGXXnpJrVq10p133lnsdg4fPqyPP/5YXbp0Uffu3Yst88ILL+jtt9/WxIkTZbfbPdYHBATo6aef1sCBA3XHHXdo0KBBOnr0qMaOHetxuTAmJkY333yzJk6cqLp166pp06ZatmyZPvrooxLb2NvGjx+vW265RV26dNGQIUNUWFioKVOmKDw83OMSckmioqL00EMPaffu3brkkku0ePFivf7663rooYeszOP5cKy4QPlx0D1wXpo7d67p06ePufjii014eLix2+2mSZMmpm/fvmbTpk0e5d9++21zzTXXmJCQEBMeHm6uuuoqt7uVjDHmjTfeMG3atDHBwcEmMjLSdO/e3WPagH79+pmwsLBi65Sfn2+mTp1qrrzySms/LVu2NP/7v/9rfvnll1KPJzc31wwcONDUr1/f2Gw2I8ns3LnTGFPyFALGGDN79mxz6aWXGofDYZo3b24mTpxoZs2a5fb58rTBypUrzS233GLq1atn7Ha7iYuLM7fccouZN2+eVcZ1d+F3331nbr31VhMeHm5q165tevfubfbv3++2vXPvLjTGmMOHD5uUlBTTqFEjExQUZJo2bWpGjhxpTVnh8uOPP5obbrjB1KpVy0jy2I7LwoULjSTz4osvFt+4xpjPP//cSDLPP/+8yc3NNVOnTjV//vOfTZMmTYzD4TAhISGmVatW5u9//7s5fPiw22fPbv8XX3zRSDILFy4scV+uOyjPvdP0XG+88Ya5+OKLTXBwsLnkkkvM7Nmzi70L8NdffzV33323qVevnomMjDT33XefWbt2bbF33JV0bpZ0d2Fx51XTpk097upcsGCBueKKK0xwcLBp0qSJmTRpknn00UdN3bp1Sz1GY4rOgcsuu8ysWLHCtGvXzjgcDtOoUSMzatQok5+f7/VjLc9xFaekuwuL25/rZwHVm82Y37ntAQB8ZOzYsRo3bpwOHjxY4TFUqN7y8/PVtm1bxcXFKTU11d/VASqFy4UAAL8ZMGCAOnXqpEaNGikzM1MzZ87U5s2b9dJLL/m7akClEWQBAPzm2LFjevzxx3Xw4EHZ7XZdffXVWrx4sdsYOqC64nIhAABAFWAKBwAAgCpAkAUAAFAFCLIAAACqAAPf/cTpdCojI0O1a9f2+uMqAABA1TDG6NixY4qNjVVAQOm5KoIsP8nIyCjxWW8AAOD8tmfPHjVu3LjUMgRZfuJ6ltWePXvK9WR7AADgP9nZ2YqPjy/TMykJsvzEdYkwIiKCIAsAgGqmLEN9GPgOAABQBQiyAAAAqgBBFgAAQBUgyAIAAKgCBFkAAABVgCALAACgChBkAQAAVAGCLAAAgCpAkAUAAFAFCLIAAACqAEEWAABAFSDIAgAAqAI8IBoAqjljjE7lF+pYToHyC51u64ICAlS/tkOBAb//MFt4lzFGxnguD/DSd2GMUW6B8/SrUHkFTo8ywUEBigixyxEUUKYHGnurXifzis7HAqfn+RgdHqygwN/P8biOLzsnv9hjK4vgoAA1qB1Soc96A0EWfCInv7BCnwsODCjTL6RTeYVK23FIy7cc1Lc7jyjvnI4mMtSu9i2i9MdL6uvqJnUVHFTyD/jh47lavy9LGzOydSK3wG1dgdMo62S+fjuZp6On8pV1Mt9jXzab1LB2iOLqhiquTqji6oaqTqjd7Rec0xidyC3QsZwCZZ/K17HcAuWebiNXOZtNyi1w6lReYdErv/hfokGBNjmCAhQcFCBHUKDsgTbZVLFfpgEBRfsPsEkBNs+thNgD1SgyRHF1aym2Toji6oQqxB7oVuboyXxtyczWlsxj2vJrtn7ef9zj+7fZpNqOIIWHBKm2w67wkKASvxPb6fI22U7//wynkY7nFuhYTr6yTxUoOydfuee0kU1Sk6hauiIuUpfHReqKuEg1igzx6HBO5BZoz28ntffIKe357aQOHstVodMUvYyR02kUFBigWsGBCrEHKtQeKIc9QAFnbccY6XhuvvZn52p/do72Z+fo0PE8Oc/paQNtNgUHBSjEHqgQe9H/A8+pT6ExyskvVG6BUzn5RZ3ouR12gdOpYzlF51Ghs5je/DR7oE1xdUIVX6+WmtSrpbq1gnX27pzG6HhOgbJPn4/FtaMxReUKnUWBQ6ExMsVEEDabTYG2ou8qMMBWdB4VczraTpd1fafnfh8Bpz9vDwxQYIBNQQEBHtspdBa1kaudcgucxdbp9xjrP9b/ilVUD5uCAovqc27g6jRGJ3MLdTy3QMdzC3Qit0AFxXwvQQG20+dP0fcfHBTwuz+xTiPlnQ6mXMdansDDHmhT+OmfuXPPtbNZv3/OWW4kq21LaqOCQqNjOfk6nlugUk5HBdikhhEhahQZotg6oQoOCtCxnAIdzynQsdx865w+lpOv/MLyf59nu7pJHX308A2V2kZl2ExFzkhUWnZ2tiIjI5WVlaWIiAh/V6fK5Bc69fd//6QFP+yr0OeDAwPUMNKhRhGhiokMUYPaDre/gIyMfs48prTthz06hZKEBQfq+uZRahDhcFt+5ESeNuzL1r6jpypUV1QfofZAtw7Sefov7+ouwCbZz8kQFJwOFFGz2U5/9+cGR3mFzmKzab7grfOxpGMri7bxdTT3f5Mq8MmSlaf/JpOFKlPoNBr+4TotWpdR4W3kFTq158gp7Tny+4FPXJ1QdWxZX3+8uL7qhQW7rdt1+KS++uWgvvrlkA6fyNOyLQdK3Vbz+mG6Ii5SUWHugVhggFSnVrAiQ+2qU8uuOqHBCrG7/xLJK3Rqf3aO9v12SvuOntLe307p+DkZMZukMEeQIkLsqh0SpNohQVZGyJii4NEYyREUWJQ5CS7KnNgDbW5/8ZvTmYW8s/6yPTezVh7GGDlPZyycxfwiPJZboIyjp5RxNEf7jp7SkRN5HmUCbFLz+uFqGVNbrRpF6NKGtVWnlt2tTIGzKJN3PLcoe3IsJ18FxfzFenZbGNeCs9lsCncEKiLErohQu9WOZ/8yzi802nbgmNbvy9L6fdnauv+YTpWQWa1Ty67GdUMVX7eWGkaEyB5oU0BAUWYmMMCm/MKizIkrs5iTX+jxV32t4EDFRISoQUSIGkY4VD/c4XFp5OwMTE6BsyjT53lopzNdgXIEBcgR5Jk5CQiwqbYjSLVPn0e1ggM9MkKFTqP92TnafeRk0evwSY/zUZJqhwSdbsei7YXYAzwyoq7sVFGmqijjeS6nOX1enpX1Opf1nZ4+14rrco0xyi80KnA6i/5fzPkRGKDT7VOUEXIEBRZbp7KwnZVxK24TRkWZmkKnUb7TqYJC45GhdP1chzmCirJGjiCPLJVRUUbKdf7klJChPldAgE3BgQFynD7O4NPnhOPsDHYxGSqn0+hEXlFm6Pjp7HlxuSjXoRh5/phZx2c7k1kurpUCA4qyZREhRRmzULvn+eh0Gh06nqt9R0/p16wcZRw9pQKnOf170H76fD5zToeHBCk8OMhrl1h9jUyWn9T0TJbTaTRi/k+a991e2QNteqXP1Wp/UXS5tmGMUXZOgX49/cOYmZWjg8dzPTr/BhEOdbi0gS5uEP67Yw6cTqNNv2Zr9c4jOpXn3tGEBgfpstgIXRYbodoh9hK2gLPl5Bd6XA4JDgwo9XKsv+XkF2p/do7H8nphwXzvAH4XmSz4lTFGYxdt1Lzv9irAJr3U6yp1viymQtuqHWJXXJ1Qr9UtIMCmy0+PzUHlnTseqzoIsQeqaVSYv6sB4AJAkIVKOZaTr+92/eaWfF7580G9nbZLNpv0fI8r1e2KRn6rHwAA/kKQhQrb+9tJ3fnPVTpwLLfY9c/efoXuuKqxj2sFAMD5gSALFZJ1Ml/956zRgWO5ig53qFHkmXlIAgNsuu/6pro7kQALAHDhIshCueUWFOrBd9Zq24HjiokI0UcPt1esF8dNAQBQE5y/twDhvOR0Gj0+7yet3nlE4Y4gzfmfawiwAAAoBpkslKjQaXTgmPut7nO+SdeidRkKCrBp5n2JatWo5k0/AQCANxBkoVjGGN05Y5XW7Tla7PrJd7XRHy4u37xXAABcSAiyUKwCp7ECrKCAMzMhhwQFaminS3QXg9oBACgVQRaKdfZzANeP7aLQ4Oo36SQAAP7EwHcU6+xnaZ3Pj0gBAOB8Re+JYrmCrKAAm8dDaQEAwO8jyEKxcgsKJZHFAgCgouhBUSxXJstBkAUAQIXQg6JYroHvZLIAAKgYelAUK9fKZHFXIQAAFUGQhWLlkckCAKBS6EFRLGvgeyCnCAAAFUEPimJZA9/tnCIAAFQEPSiKZQ18J5MFAECF0IOiWGcyWQx8BwCgIgiyUKy8QjJZAABUBj0oipWbXzTwnclIAQCoGHpQFMuVySLIAgCgYuhBUazcfObJAgCgMuhBUSwyWQAAVA49KIrFswsBAKicatGDpqena8CAAWrWrJlCQ0PVokULjRkzRnl5eVaZw4cPq2vXroqNjZXD4VB8fLwGDx6s7Oxst22tX79eycnJCg0NVVxcnMaPHy9jjFuZlStXKjExUSEhIWrevLlmzpzpUaf58+erdevWcjgcat26tRYsWFA1B+8nPFYHAIDKqRY96JYtW+R0OvXqq69q48aNeuGFFzRz5kyNGjXKKhMQEKDu3bvrk08+0datW/Xmm29q6dKlSklJscpkZ2erU6dOio2N1Zo1azR9+nRNnTpV06ZNs8rs3LlT3bp104033qgffvhBo0aN0qOPPqr58+dbZdLS0tSzZ0/17dtX69atU9++fdWjRw+tXr3aNw3iAzwgGgCAyrGZc9M41cSUKVM0Y8YM7dixo8QyL7/8sqZMmaI9e/ZIkmbMmKGRI0dq//79cjgckqRJkyZp+vTp2rt3r2w2m0aMGKFPPvlEmzdvtraTkpKidevWKS0tTZLUs2dPZWdn67PPPrPKdO3aVXXr1tX7779fpvpnZ2crMjJSWVlZioiIKPfxV7XhH/6oj77fpyf+3FIpyS38XR0AAM4L5em/q0UmqzhZWVmqV69eieszMjL00UcfKTk52VqWlpam5ORkK8CSpC5duigjI0Pp6elWmc6dO7ttq0uXLlq7dq3y8/NLLbNq1aoS65Obm6vs7Gy31/nMmvGdy4UAAFRItexBt2/frunTp7tdCnTp3bu3atWqpbi4OEVEROiNN96w1mVmZqphw4Zu5V3vMzMzSy1TUFCgQ4cOlVrGtY3iTJw4UZGRkdYrPj6+HEfsewx8BwCgcvzag44dO1Y2m63U19q1a90+k5GRoa5du+qee+7RwIEDPbb5wgsv6Pvvv9fChQu1fft2DR8+3G29zWZze++6Wnr28oqWOXfZ2UaOHKmsrCzr5bqEeb7KY0wWAACVEuTPnQ8ePFi9evUqtUxCQoL174yMDHXs2FFJSUl67bXXii0fExOjmJgYtWzZUlFRUbrxxhs1evRoNWrUSDExMR7ZpgMHDkg6k9EqqUxQUJCioqJKLXNudutsDofD7TLl+Y67CwEAqBy/BlnR0dGKjo4uU9l9+/apY8eOSkxM1Jw5cxQQ8PudvysDlZubK0lKSkrSqFGjlJeXp+DgYElSamqqYmNjrWAuKSlJixYtcttOamqq2rVrJ7vdbpVZsmSJhg0b5lamffv2ZTqW6iC3oOjZhTwgGgCAiqkWPWhGRoY6dOig+Ph4TZ06VQcPHlRmZqZbNmnx4sWaM2eONmzYoPT0dC1evFgPPfSQbrjhBiuA6tOnjxwOh/r3768NGzZowYIFmjBhgoYPH25d6ktJSdGuXbs0fPhwbd68WbNnz9asWbP0+OOPW/saMmSIUlNTNXnyZG3ZskWTJ0/W0qVLNXToUF82S5WyZny3V4tTBACA84+pBubMmWMkFfty+fLLL01SUpKJjIw0ISEh5uKLLzYjRowwv/32m9u2fvrpJ3PjjTcah8NhYmJizNixY43T6XQrs2LFCnPVVVeZ4OBgk5CQYGbMmOFRp3nz5plLL73U2O1207JlSzN//vxyHVNWVpaRZLKyssr1OV+5+fkVpumIT803vxz0d1UAADhvlKf/rrbzZFV35/s8WclTlmvX4ZOa/1CSEpuWPFUGAAAXkgtinixULWvgeyB3FwIAUBEEWSgW82QBAFA59KAoFjO+AwBQOfSgKJY1hQNBFgAAFUIPCg9Op1F+YdH9EGSyAACoGHpQeHDNkSWRyQIAoKLoQeHBNehdIsgCAKCi6EHhIe/sIIvH6gAAUCH0oPBw9qB31+OGAABA+RBkwQPTNwAAUHn0ovBgPRyaIAsAgAqjF4WH3HxXkMUjdQAAqCiCLHhwZbK4sxAAgIqjF4UHVyaLOwsBAKg4elF4yCssurvQYef0AACgouhF4cF1dyGZLAAAKo5eFB5cM76TyQIAoOLoReEhl0wWAACVRi8KD1aQxd2FAABUGL0oPJyZ8Z15sgAAqCiCLHjII5MFAECl0YvCg+sB0TxWBwCAiqMXhQcyWQAAVB69KDww8B0AgMqjF4UHBr4DAFB5BFnwcCbI4vQAAKCi6EXhgYHvAABUHr0oPOQVMiYLAIDKoheFh9x8LhcCAFBZ9KLwQCYLAIDKoxeFB1cmKziQuwsBAKgogix4yC3kciEAAJVFLwoPzPgOAEDl0YvCA1M4AABQefSi8EAmCwCAyqMXhQeeXQgAQOXRi8IDzy4EAKDyCLLggWcXAgBQefSi8MDAdwAAKo9eFG4KCp1ymqJ/MyYLAICKoxeFG9egd4kgCwCAyqAXhZu8s4OsQE4PAAAqil4UblwPhw4MsCmIIAsAgAqjF4Ub18OhGfQOAEDl0JPCTV5h0Z2FjMcCAKBy6EnhJodMFgAAXkFPCjeuMVlksgAAqBx6UrixHg7NoHcAACqFnhRucnluIQAAXkGQBTdWJovLhQAAVAo9Kdzw3EIAALyDnhRuyGQBAOAd9KRwk1fAFA4AAHgDPSncMPAdAADvqBZBVnp6ugYMGKBmzZopNDRULVq00JgxY5SXl1ds+cOHD6tx48ay2Ww6evSo27r169crOTlZoaGhiouL0/jx42WMcSuzcuVKJSYmKiQkRM2bN9fMmTM99jF//ny1bt1aDodDrVu31oIFC7x2vP7E5UIAALyjWvSkW7ZskdPp1KuvvqqNGzfqhRde0MyZMzVq1Khiyw8YMEBt2rTxWJ6dna1OnTopNjZWa9as0fTp0zV16lRNmzbNKrNz505169ZNN954o3744QeNGjVKjz76qObPn2+VSUtLU8+ePdW3b1+tW7dOffv2VY8ePbR69WrvH7yPMfAdAAAvMdXUc889Z5o1a+ax/J///KdJTk42y5YtM5LMb7/95rYuMjLS5OTkWMsmTpxoYmNjjdPpNMYY8/e//920bNnSbZv/+7//a66//nrrfY8ePUzXrl3dynTp0sX06tWrzPXPysoykkxWVlaZP+MLz3+xxTQd8akZvXC9v6sCAMB5pzz9d7VNV2RlZalevXpuyzZt2qTx48fr7bffVkCA56GlpaUpOTlZDofDWtalSxdlZGQoPT3dKtO5c2e3z3Xp0kVr165Vfn5+qWVWrVpVYn1zc3OVnZ3t9jof5RYy4zsAAN5QLXvS7du3a/r06UpJSbGW5ebmqnfv3poyZYqaNGlS7OcyMzPVsGFDt2Wu95mZmaWWKSgo0KFDh0ot49pGcSZOnKjIyEjrFR8fX8aj9a1c1wOi7dXy1AAA4Lzh15507Nixstlspb7Wrl3r9pmMjAx17dpV99xzjwYOHGgtHzlypFq1aqX77ruv1H3abDa39+b0oPezl1e0zLnLzjZy5EhlZWVZrz179pRaT3+xHhAdyN2FAABURpA/dz548GD16tWr1DIJCQnWvzMyMtSxY0clJSXptddecyv35Zdfav369fr3v/8t6UxgFB0drSeffFLjxo1TTEyMR7bpwIEDks5ktEoqExQUpKioqFLLnJvdOpvD4XC7THm+IpMFAIB3+DXIio6OVnR0dJnK7tu3Tx07dlRiYqLmzJnjMeZq/vz5OnXqlPV+zZo1euCBB/TVV1+pRYsWkqSkpCSNGjVKeXl5Cg4OliSlpqYqNjbWCuaSkpK0aNEit22npqaqXbt2stvtVpklS5Zo2LBhbmXat29fvgY4D+UxJgsAAK+oFj1pRkaGOnTooPj4eE2dOlUHDx5UZmamWzapRYsWuvzyy61Xs2bNJEmtWrVSgwYNJEl9+vSRw+FQ//79tWHDBi1YsEATJkzQ8OHDrUt9KSkp2rVrl4YPH67Nmzdr9uzZmjVrlh5//HFrX0OGDFFqaqomT56sLVu2aPLkyVq6dKmGDh3qu0apInmuKRzIZAEAUCl+zWSVVWpqqrZt26Zt27apcePGbuvMOROJliYyMlJLlizRI488onbt2qlu3boaPny4hg8fbpVp1qyZFi9erGHDhumVV15RbGysXn75Zd11111Wmfbt2+uDDz7QU089pdGjR6tFixaaO3eurrvuusofrJ+5ZnwnkwUAQOXYTHmiFHhNdna2IiMjlZWVpYiICH9Xx9Ln9f/Tqu2H9VKvtureNs7f1QEA4LxSnv6bdAXc8OxCAAC8gyALbvKsIItTAwCAyqAnhRuCLAAAvIOeFG5cD4gOJsgCAKBS6EnhxpXJIsgCAKBy6EnhhoHvAAB4B0EW3JDJAgDAO+hJ4SaXge8AAHgFPSksxpgzzy4kyAIAoFLoSWFxBVgSQRYAAJVFTwqL61KhxOVCAAAqi54UlryzgiweEA0AQOXQk8KSe9adhTabzc+1AQCgeiPIgsV6pA5ZLAAAKo3eFBYryLJzWgAAUFn0prBYzy0kkwUAQKXRm8LCbO8AAHgPvSksPLcQAADvIciChUwWAADeQ28KC88tBADAe+hNYbEGvhNkAQBQafSmsHC5EAAA76E3hYXLhQAAeA+9KSxnMlncXQgAQGURZMGSV0gmCwAAb6E3hSU3nzFZAAB4C70pLHmFPFYHAABvoTeFxZXJ4gHRAABUHr0pLNaYLDJZAABUGr0pLK67Cx127i4EAKCyCLJgcc2TxZgsAAAqj94UFmZ8BwDAe+hNYXE9u5B5sgAAqDx6U1hyyWQBAOA19KawWAPfeawOAACVRpAFC5ksAAC8h94UljOZLE4LAAAqi94UFtfAdzJZAABUHr0pLK4Z3wmyAACoPHpTWLhcCACA99CbwpJLkAUAgNfQm8LCFA4AAHgPQRYsTOEAAID30JtCklToNCp0Gkk8IBoAAG+gN4WkM5cKJclh57QAAKCyKtWb5uXl6eeff1ZBQYG36gM/cc2RJZHJAgDAGyrUm548eVIDBgxQrVq1dNlll2n37t2SpEcffVSTJk3yagXhG65MVmCATUEEWQAAVFqFetORI0dq3bp1WrFihUJCQqzlN998s+bOneu1ysF3rEHvBFgAAHhFUEU+tHDhQs2dO1fXX3+9bDabtbx169bavn271yoH3+HOQgAAvKtCPerBgwfVoEEDj+UnTpxwC7pQfbjGZDERKQAA3lGhHvWaa67Rf/7zH+u9K7B6/fXXlZSU5J2awafyyGQBAOBVFbpcOHHiRHXt2lWbNm1SQUGBXnrpJW3cuFFpaWlauXKlt+sIH+C5hQAAeFeFetT27dtr1apVOnnypFq0aKHU1FQ1bNhQaWlpSkxM9HYd4QNnxmTxSB0AALyh3Jms/Px8Pfjggxo9erTeeuutqqgT/IBMFgAA3lXuHtVut2vBggVVUZcSpaena8CAAWrWrJlCQ0PVokULjRkzRnl5eW7lbDabx2vmzJluZdavX6/k5GSFhoYqLi5O48ePlzHGrczKlSuVmJiokJAQNW/e3GMbkjR//ny1bt1aDodDrVu39nmbeBt3FwIA4F0V6lHvuOMOLVy40MtVKdmWLVvkdDr16quvauPGjXrhhRc0c+ZMjRo1yqPsnDlz9Ouvv1qvfv36Weuys7PVqVMnxcbGas2aNZo+fbqmTp2qadOmWWV27typbt266cYbb9QPP/ygUaNG6dFHH9X8+fOtMmlpaerZs6f69u2rdevWqW/fvurRo4dWr15dtQ1RhfIKubsQAABvsplz0zhl8Oyzz2rq1Km66aablJiYqLCwMLf1jz76qNcqWJIpU6ZoxowZ2rFjh7XMZrNpwYIFuv3224v9zIwZMzRy5Ejt379fDodDkjRp0iRNnz5de/fulc1m04gRI/TJJ59o8+bN1udSUlK0bt06paWlSZJ69uyp7OxsffbZZ1aZrl27qm7dunr//ffLVP/s7GxFRkYqKytLERER5T18r5u7ZrdGzF+vm1s10Bv9rvF3dQAAOC+Vp/+uUNrijTfeUJ06dfTdd9/ptdde0wsvvGC9XnzxxYpsstyysrJUr149j+WDBw9WdHS0rrnmGs2cOVNO55kHH6elpSk5OdkKsCSpS5cuysjIUHp6ulWmc+fObtvs0qWL1q5dq/z8/FLLrFq1qsT65ubmKjs72+11PuFyIQAA3lWhKRx27tzp7XqUy/bt2zV9+nQ9//zzbsuffvpp3XTTTQoNDdWyZcv02GOP6dChQ3rqqackSZmZmUpISHD7TMOGDa11zZo1U2ZmprXs7DIFBQU6dOiQGjVqVGKZzMzMEus8ceJEjRs3rqKHXOXODHzn7kIAALyh0mkLY4zHwPGyGjt2bLGD1c9+rV271u0zGRkZ6tq1q+655x4NHDjQbd1TTz2lpKQktW3bVo899pjGjx+vKVOmuJU5d0Z6V93PXl7RMqXNdj9y5EhlZWVZrz179pRY1h94diEAAN5VoUyWJL399tuaMmWKfvnlF0nSJZdcor/97W/q27dvmbcxePBg9erVq9QyZ2eeMjIy1LFjRyUlJem111773e1ff/31ys7O1v79+9WwYUPFxMR4ZJsOHDgg6UxGq6QyQUFBioqKKrXMudmtszkcDrfLlOcbLhcCAOBdFQqypk2bptGjR2vw4MG64YYbZIzRN998o5SUFB06dEjDhg0r03aio6MVHR1dprL79u1Tx44dlZiYqDlz5igg4PeDgR9++EEhISGqU6eOJCkpKUmjRo1SXl6egoODJUmpqamKjY21grmkpCQtWrTIbTupqalq166d7Ha7VWbJkiVux5mamqr27duX6VjOBy8s2ap1e49a73ccPCGJuwsBAPCWCgVZ06dP14wZM3T//fdby7p3767LLrtMY8eOLXOQVVYZGRnq0KGDmjRpoqlTp+rgwYPWupiYGEnSokWLlJmZqaSkJIWGhmr58uV68skn9eCDD1oZpD59+mjcuHHq37+/Ro0apV9++UUTJkzQP/7xD+tSX0pKiv7f//t/Gj58uAYNGqS0tDTNmjXL7a7BIUOG6I9//KMmT56s7t276+OPP9bSpUv19ddfe/W4q8re307qpWW/FLsuJjLEx7UBAKCGMhXgcDjML7/84rF869atxuFwVGSTpZozZ46RVOzL5bPPPjNt27Y14eHhplatWubyyy83L774osnPz3fb1k8//WRuvPFG43A4TExMjBk7dqxxOp1uZVasWGGuuuoqExwcbBISEsyMGTM86jRv3jxz6aWXGrvdblq2bGnmz59frmPKysoykkxWVla5PucNa9MPm6YjPjWJT6eaeWv3WK/P1meYnPwCn9cHAIDqojz9d4Xmybr88svVp08fj8lAn3nmGc2dO1fr16+vdPBX0/lznqzPN/yqlHe/11VN6mjBwzf4dN8AAFRn5em/K3S5cNy4cerZs6f++9//6oYbbpDNZtPXX3+tZcuW6cMPP6xQpeE7B48XPY6ofvj5OxAfAIDqrkKjnO+66y6tXr1a0dHRWrhwoT766CNFR0fr22+/1R133OHtOsLLDh7LlSTVr02QBQBAVanwFA6JiYl69913vVkX+AhBFgAAVa9CmazFixfriy++8Fj+xRdfuD3PD+cngiwAAKpehYKsJ554QoWFhR7LjTF64oknKl0pVK2Dx08HWYzJAgCgylQoyPrll1/UunVrj+UtW7bUtm3bKl0pVK1DZLIAAKhyFQqyIiMjtWPHDo/l27ZtU1hYWKUrhapjjLEuF0aTyQIAoMpUKMi67bbbNHToUG3fvt1atm3bNj322GO67bbbvFY5eF92ToHyCoueU0gmCwCAqlOhIGvKlCkKCwtTy5Yt1axZMzVr1kwtW7ZUVFSUpk6d6u06wotcWazaIUEKsQf6uTYAANRcFZrCITIyUqtWrdKSJUu0bt06hYaG6sorr9SNN97o7frBy7izEAAA3yhXJmv16tXWFA02m02dO3dWgwYNNHXqVN1111168MEHlZubWyUVhXdwZyEAAL5RriBr7Nix+umnn6z369ev16BBg9SpUyc98cQTWrRokSZOnOj1SsJ7yGQBAOAb5QqyfvzxR910003W+w8++EDXXnutXn/9dQ0fPlwvv/wyzy48zxFkAQDgG+UKsn777Tc1bNjQer9y5Up17drVen/NNddoz5493qsdvI4gCwAA3yhXkNWwYUPt3LlTkpSXl6fvv/9eSUlJ1vpjx47Jbrd7t4bwqkPHmSMLAABfKFeQ1bVrVz3xxBP66quvNHLkSNWqVcvtjsKffvpJLVq08Hol4T1ksgAA8I1yTeHwzDPP6M4771RycrLCw8P11ltvKTg42Fo/e/Zsde7c2euVhPdwdyEAAL5RriCrfv36+uqrr5SVlaXw8HAFBrpPZjlv3jyFh4d7tYLwnkKn0eHTQVYDMlkAAFSpCk9GWpx69epVqjKoWkdO5MlpJJtNqhcW/PsfAAAAFVahx+qgenKNx4oKC1ZQIF89AABViZ72AnKQOwsBAPAZgqwLyCHuLAQAwGcIsi4g3FkIAIDvEGRdQJgjCwAA3yHIuoAQZAEA4DsEWRcQgiwAAHyHIOsCwpgsAAB8hyDrAkImCwAA3yHIukDkFhQq61S+JIIsAAB8gSDrAnH4eJ4kyR5oU2So3c+1AQCg5iPIukC4LhVGhztks9n8XBsAAGo+gqwLBOOxAADwLYKsCwR3FgIA4FsEWRcIMlkAAPgWQdYFgiALAADfIsi6QBw6TpAFAIAvEWRdIKxMFmOyAADwCYKsC8RBMlkAAPgUQdYF4ux5sgAAQNUjyLoAnMgt0Mm8QklksgAA8BWCrAuAK4tVKzhQYY4gP9cGAIALA0HWBYDxWAAA+B5B1gXgEHcWAgDgcwRZFwAyWQAA+B5B1gWA2d4BAPA9gqwLABORAgDgewRZF4CjJ/MlSXXCgv1cEwAALhwEWReAU/lFc2TVsgf6uSYAAFw4CLIuAK4gKzSYIAsAAF8hyLoA5JwOskLsfN0AAPgKve4F4FSeK8gikwUAgK8QZF0ArMuFBFkAAPgMQdYFICffKYkxWQAA+BJB1gUgh0wWAAA+Vy2CrPT0dA0YMEDNmjVTaGioWrRooTFjxigvL8+j7Jtvvqk2bdooJCREMTExGjx4sNv69evXKzk5WaGhoYqLi9P48eNljHErs3LlSiUmJiokJETNmzfXzJkzPfYzf/58tW7dWg6HQ61bt9aCBQu8e9BeYoyxLhcyJgsAAN8J8ncFymLLli1yOp169dVXddFFF2nDhg0aNGiQTpw4oalTp1rlpk2bpueff15TpkzRddddp5ycHO3YscNan52drU6dOqljx45as2aNtm7dqv79+yssLEyPPfaYJGnnzp3q1q2bBg0apHfffVfffPONHn74YdWvX1933XWXJCktLU09e/bU008/rTvuuEMLFixQjx499PXXX+u6667zbeP8jvxCo0JnURBJkAUAgO/YzLlpnGpiypQpmjFjhhVE/fbbb4qLi9OiRYt00003FfuZGTNmaOTIkdq/f78cjqJHzEyaNEnTp0/X3r17ZbPZNGLECH3yySfavHmz9bmUlBStW7dOaWlpkqSePXsqOztbn332mVWma9euqlu3rt5///0y1T87O1uRkZHKyspSREREhdqgLLJO5evKcamSpK3P/FnBQdUieQkAwHmpPP13te1xs7KyVK9ePev9kiVL5HQ6tW/fPrVq1UqNGzdWjx49tGfPHqtMWlqakpOTrQBLkrp06aKMjAylp6dbZTp37uy2ry5dumjt2rXKz88vtcyqVatKrG9ubq6ys7PdXr6Qe/pSYWCATfZAm0/2CQAAqmmQtX37dk2fPl0pKSnWsh07dsjpdGrChAl68cUX9e9//1tHjhxRp06drLFbmZmZatiwodu2XO8zMzNLLVNQUKBDhw6VWsa1jeJMnDhRkZGR1is+Pr6CR18+Z0/fYLMRZAEA4Ct+DbLGjh0rm81W6mvt2rVun8nIyFDXrl11zz33aODAgdZyp9Op/Px8vfzyy+rSpYuuv/56vf/++/rll1+0fPlyq9y5gYbraunZyytaprQgZuTIkcrKyrJeZ2fYqhKD3gEA8A+/DnwfPHiwevXqVWqZhIQE698ZGRnq2LGjkpKS9Nprr7mVa9SokSSpdevW1rL69esrOjpau3fvliTFxMR4ZJsOHDgg6UxGq6QyQUFBioqKKrXMudmtszkcDrfLlL5yZrb3apm0BACg2vJrkBUdHa3o6Ogyld23b586duyoxMREzZkzRwEB7kHDDTfcIEn6+eef1bhxY0nSkSNHdOjQITVt2lSSlJSUpFGjRikvL0/BwcGSpNTUVMXGxlrBXFJSkhYtWuS27dTUVLVr1052u90qs2TJEg0bNsytTPv27cvZAlWP2d4BAPCPapHeyMjIUIcOHRQfH6+pU6fq4MGDyszMdMsmXXLJJerevbuGDBmiVatWacOGDerXr59atmypjh07SpL69Okjh8Oh/v37a8OGDVqwYIEmTJig4cOHW5f6UlJStGvXLg0fPlybN2/W7NmzNWvWLD3++OPWvoYMGaLU1FRNnjxZW7Zs0eTJk7V06VINHTrUp+1SFtZEpMz2DgCAb5lqYM6cOUZSsa+zZWVlmQceeMDUqVPH1KtXz9xxxx1m9+7dbmV++uknc+ONNxqHw2FiYmLM2LFjjdPpdCuzYsUKc9VVV5ng4GCTkJBgZsyY4VGnefPmmUsvvdTY7XbTsmVLM3/+/HIdU1ZWlpFksrKyyvW58vrPTxmm6YhPzT0zV1XpfgAAuBCUp/+utvNkVXe+midr/nd79di8dUq+pL7eeuDaKtsPAAAXggtiniyUzZm7C/mqAQDwJXreGo6HQwMA4B8EWTWcawoHBr4DAOBbBFk1HJORAgDgHwRZNVxOvlMSlwsBAPA1gqwajslIAQDwD4KsGi6Hy4UAAPgFQVYNZz27kIHvAAD4FEFWDcflQgAA/IMgq4ZjniwAAPyDIKuGO/OAaL5qAAB8iZ63hrPmyQoikwUAgC8RZNVwVpDFwHcAAHyKIKuGO5XHZKQAAPgDQVYNx8B3AAD8gyCrhjsz8J0gCwAAXyLIqsHyC50qcBpJzPgOAICvEWTVYK5B75IUYuerBgDAl+h5a7Cc04/UCbBJwYF81QAA+BI9bw129iN1bDabn2sDAMCFhSCrBjvFoHcAAPyGIKsGy8kvmiOLQe8AAPgeQVYNdur0mCyCLAAAfI8gqwZjIlIAAPyHIKsGO0WQBQCA3xBk1WDW5UIGvgMA4HMEWTVYToErk8XXDACAr9H71mCuTBaXCwEA8D2CrBrMNfCduwsBAPA9gqwa7BRBFgAAfkOQVYOdyiuajJQZ3wEA8D2CrBqMKRwAAPAfgqwaLJcgCwAAvyHIqsGsMVlcLgQAwOcIsmowK8gK4msGAMDX6H1rMGueLDJZAAD4HEFWDcYDogEA8B+CrBqMuwsBAPAfgqwaLCe/aJ4sBr4DAOB7BFk12JmB7wRZAAD4GkFWDZbDwHcAAPyGIKsGY0wWAAD+Q5BVQ+UXOlXgNJIIsgAA8AeCrBrKNX2DJIUE8zUDAOBr9L41lOtSYYBNCg7kawYAwNfofWuonLzT0zfYA2Wz2fxcGwAALjwEWTUUg94BAPAvgqwaypojiyALAAC/IMiqoXg4NAAA/kWQVUPlFHC5EAAAfyLIqqFcs72H2PmKAQDwB3rgGooxWQAA+BdBVg3F3YUAAPgXQVYNxcB3AAD8q1oEWenp6RowYICaNWum0NBQtWjRQmPGjFFeXp5V5s0335TNZiv2deDAAavc+vXrlZycrNDQUMXFxWn8+PEyxrjtb+XKlUpMTFRISIiaN2+umTNnetRp/vz5at26tRwOh1q3bq0FCxZUXQNUQA6ZLAAA/CrI3xUoiy1btsjpdOrVV1/VRRddpA0bNmjQoEE6ceKEpk6dKknq2bOnunbt6va5/v37KycnRw0aNJAkZWdnq1OnTurYsaPWrFmjrVu3qn///goLC9Njjz0mSdq5c6e6deumQYMG6d1339U333yjhx9+WPXr19ddd90lSUpLS1PPnj319NNP64477tCCBQvUo0cPff3117ruuut82DIly8k/M+M7AADwPZs5N41TTUyZMkUzZszQjh07il1/8OBBxcXFadasWerbt68kacaMGRo5cqT2798vh8MhSZo0aZKmT5+uvXv3ymazacSIEfrkk0+0efNma1spKSlat26d0tLSJBUFdNnZ2frss8+sMl27dlXdunX1/vvvl6n+2dnZioyMVFZWliIiIirUBqV5+tNNmvX1TqUkt9ATf27p9e0DAHAhKk//XS0uFxYnKytL9erVK3H922+/rVq1aunuu++2lqWlpSk5OdkKsCSpS5cuysjIUHp6ulWmc+fObtvq0qWL1q5dq/z8/FLLrFq1qrKH5TUMfAcAwL+qZZC1fft2TZ8+XSkpKSWWmT17tvr06aPQ0FBrWWZmpho2bOhWzvU+MzOz1DIFBQU6dOhQqWVc2yhObm6usrOz3V5VKcca+F4tv2IAAKo9v/bAY8eOLXGwuuu1du1at89kZGSoa9euuueeezRw4MBit5uWlqZNmzZpwIABHutsNpvbe9fV0rOXV7TMucvONnHiREVGRlqv+Pj4Est6A5ksAAD8y68D3wcPHqxevXqVWiYhIcH6d0ZGhjp27KikpCS99tprJX7mjTfeUNu2bZWYmOi2PCYmxiPb5Lrz0JWZKqlMUFCQoqKiSi1zbnbrbCNHjtTw4cOt99nZ2VUaaOUwGSkAAH7l1yArOjpa0dHRZSq7b98+dezYUYmJiZozZ44CAopPwh0/flwffvihJk6c6LEuKSlJo0aNUl5enoKDgyVJqampio2NtYK5pKQkLVq0yO1zqampateunex2u1VmyZIlGjZsmFuZ9u3bl1h/h8PhNhasqjHjOwAA/lUtBuxkZGSoQ4cOio+P19SpU3Xw4EFlZmYWOwZq7ty5Kigo0L333uuxrk+fPnI4HOrfv782bNigBQsWaMKECRo+fLh1qS8lJUW7du3S8OHDtXnzZs2ePVuzZs3S448/bm1nyJAhSk1N1eTJk7VlyxZNnjxZS5cu1dChQ6usDcrr1OkpHLhcCACAf1SLebJSU1O1bds2bdu2TY0bN3Zbd+4MFLNmzdKdd96punXremwnMjJSS5Ys0SOPPKJ27dqpbt26Gj58uNtlvGbNmmnx4sUaNmyYXnnlFcXGxurll1+25siSpPbt2+uDDz7QU089pdGjR6tFixaaO3fueTNHlnT2wHeCLAAA/KHazpNV3VX1PFl/fG65dh85qfkPtVdiU8+AEwAAlN8FMU8WSsfdhQAA+BdBVg1lPbuQy4UAAPgFQVYNdWYKB75iAAD8gR64BsovdCq/sGioHZcLAQDwD4KsGsiVxZKYJwsAAH8hyKqBXIPebTbJEcRXDACAP9AD10A5eWcmIi3teYoAAKDqEGTVQDkFPFIHAAB/I8iqgU7lMUcWAAD+RpBVA51i+gYAAPyOXrgGOsVEpAAA+B1BVg2Uw+VCAAD8jiCrBmLgOwAA/keQVQOdOj2FA0EWAAD+Q5BVA1ljsgiyAADwG4KsGiiHIAsAAL8jyKqBrHmyuLsQAAC/Iciqgc7Mk0WQBQCAvxBk1UBcLgQAwP8IsmogZnwHAMD/6IVroBxmfAcAwO8Ismog18B3xmQBAOA/BFk1EPNkAQDgfwRZNdCp/KIZ3wmyAADwH4KsGiiXKRwAAPA7gqwayLpcGMzXCwCAv9AL10AMfAcAwP8IsmogBr4DAOB/BFk1EPNkAQDgfwRZNUxBoVP5hUYSmSwAAPyJIKuGySlwWv9mTBYAAP5DkFXDuAa9S5IjiK8XAAB/oReuYXLOGvRus9n8XBsAAC5cBFk1zCkGvQMAcF4gyKphXJcLGfQOAIB/EWTVMAVOo7DgQNUikwUAgF8F+bsC8K7EpnW1cXxXGWP8XRUAAC5oZLJqKAa9AwDgXwRZAAAAVYAgCwAAoAoQZAEAAFQBgiwAAIAqQJAFAABQBQiyAAAAqgBBFgAAQBUgyAIAAKgCBFkAAABVgCALAACgChBkAQAAVAGCLAAAgCpAkAUAAFAFgvxdgQuVMUaSlJ2d7eeaAACAsnL1265+vDQEWX5y7NgxSVJ8fLyfawIAAMrr2LFjioyMLLWMzZQlFIPXOZ1OZWRkqHbt2rLZbF7ddnZ2tuLj47Vnzx5FRER4ddtwR1v7Dm3tO7S179DWvuOttjbG6NixY4qNjVVAQOmjrshk+UlAQIAaN25cpfuIiIjgh9ZHaGvfoa19h7b2Hdrad7zR1r+XwXJh4DsAAEAVIMgCAACoAgRZNZDD4dCYMWPkcDj8XZUaj7b2Hdrad2hr36Gtfccfbc3AdwAAgCpAJgsAAKAKEGQBAABUAYIsAACAKkCQBQAAUAUIsmqYf/7zn2rWrJlCQkKUmJior776yt9VqvYmTpyoa665RrVr11aDBg10++236+eff3YrY4zR2LFjFRsbq9DQUHXo0EEbN270U41rjokTJ8pms2no0KHWMtrae/bt26f77rtPUVFRqlWrltq2bavvvvvOWk9be0dBQYGeeuopNWvWTKGhoWrevLnGjx8vp9NplaGtK+6///2vbr31VsXGxspms2nhwoVu68vStrm5ufrrX/+q6OhohYWF6bbbbtPevXsrXzmDGuODDz4wdrvdvP7662bTpk1myJAhJiwszOzatcvfVavWunTpYubMmWM2bNhgfvzxR3PLLbeYJk2amOPHj1tlJk2aZGrXrm3mz59v1q9fb3r27GkaNWpksrOz/Vjz6u3bb781CQkJpk2bNmbIkCHWctraO44cOWKaNm1q+vfvb1avXm127txpli5darZt22aVoa2945lnnjFRUVHm008/NTt37jTz5s0z4eHh5sUXX7TK0NYVt3jxYvPkk0+a+fPnG0lmwYIFbuvL0rYpKSkmLi7OLFmyxHz//femY8eO5sorrzQFBQWVqhtBVg1y7bXXmpSUFLdlLVu2NE888YSfalQzHThwwEgyK1euNMYY43Q6TUxMjJk0aZJVJicnx0RGRpqZM2f6q5rV2rFjx8zFF19slixZYpKTk60gi7b2nhEjRpg//OEPJa6nrb3nlltuMQ888IDbsjvvvNPcd999xhja2pvODbLK0rZHjx41drvdfPDBB1aZffv2mYCAAPP5559Xqj5cLqwh8vLy9N1336lz585uyzt37qxVq1b5qVY1U1ZWliSpXr16kqSdO3cqMzPTre0dDoeSk5Np+wp65JFHdMstt+jmm292W05be88nn3yidu3a6Z577lGDBg101VVX6fXXX7fW09be84c//EHLli3T1q1bJUnr1q3T119/rW7dukmiratSWdr2u+++U35+vluZ2NhYXX755ZVufx4QXUMcOnRIhYWFatiwodvyhg0bKjMz00+1qnmMMRo+fLj+8Ic/6PLLL5ckq32La/tdu3b5vI7V3QcffKDvv/9ea9as8VhHW3vPjh07NGPGDA0fPlyjRo3St99+q0cffVQOh0P3338/be1FI0aMUFZWllq2bKnAwEAVFhbq2WefVe/evSVxXlelsrRtZmamgoODVbduXY8yle0/CbJqGJvN5vbeGOOxDBU3ePBg/fTTT/r666891tH2lbdnzx4NGTJEqampCgkJKbEcbV15TqdT7dq104QJEyRJV111lTZu3KgZM2bo/vvvt8rR1pU3d+5cvfvuu/rXv/6lyy67TD/++KOGDh2q2NhY9evXzypHW1edirStN9qfy4U1RHR0tAIDAz2i7gMHDnhE8KiYv/71r/rkk0+0fPlyNW7c2FoeExMjSbS9F3z33Xc6cOCAEhMTFRQUpKCgIK1cuVIvv/yygoKCrPakrSuvUaNGat26tduyVq1aaffu3ZI4r73pb3/7m5544gn16tVLV1xxhfr27athw4Zp4sSJkmjrqlSWto2JiVFeXp5+++23EstUFEFWDREcHKzExEQtWbLEbfmSJUvUvn17P9WqZjDGaPDgwfroo4/05ZdfqlmzZm7rmzVrppiYGLe2z8vL08qVK2n7crrpppu0fv16/fjjj9arXbt2uvfee/Xjjz+qefPmtLWX3HDDDR5TkWzdulVNmzaVxHntTSdPnlRAgHt3GxgYaE3hQFtXnbK0bWJioux2u1uZX3/9VRs2bKh8+1dq2DzOK64pHGbNmmU2bdpkhg4dasLCwkx6erq/q1atPfTQQyYyMtKsWLHC/Prrr9br5MmTVplJkyaZyMhI89FHH5n169eb3r17c/u1l5x9d6ExtLW3fPvttyYoKMg8++yz5pdffjHvvfeeqVWrlnn33XetMrS1d/Tr18/ExcVZUzh89NFHJjo62vz973+3ytDWFXfs2DHzww8/mB9++MFIMtOmTTM//PCDNX1RWdo2JSXFNG7c2CxdutR8//335k9/+hNTOMDTK6+8Ypo2bWqCg4PN1VdfbU0zgIqTVOxrzpw5Vhmn02nGjBljYmJijMPhMH/84x/N+vXr/VfpGuTcIIu29p5FixaZyy+/3DgcDtOyZUvz2muvua2nrb0jOzvbDBkyxDRp0sSEhISY5s2bmyeffNLk5uZaZWjrilu+fHmxv6P79etnjClb2546dcoMHjzY1KtXz4SGhpq//OUvZvfu3ZWum80YYyqXCwMAAMC5GJMFAABQBQiyAAAAqgBBFgAAQBUgyAIAAKgCBFkAAABVgCALAACgChBkAQAAVAGCLADwk4SEBL344ov+rgaAKkKQBeCC0L9/f91+++2SpA4dOmjo0KE+2/ebb76pOnXqeCxfs2aNHnzwQZ/VA4BvBfm7AgBQXeXl5Sk4OLjCn69fv74XawPgfEMmC8AFpX///lq5cqVeeukl2Ww22Ww2paenS5I2bdqkbt26KTw8XA0bNlTfvn116NAh67MdOnTQ4MGDNXz4cEVHR6tTp06SpGnTpumKK65QWFiY4uPj9fDDD+v48eOSpBUrVuh//ud/lJWVZe1v7NixkjwvF+7evVvdu3dXeHi4IiIi1KNHD+3fv99aP3bsWLVt21bvvPOOEhISFBkZqV69eunYsWNV22gAKoQgC8AF5aWXXlJSUpIGDRqkX3/9Vb/++qvi4+P166+/Kjk5WW3bttXatWv1+eefa//+/erRo4fb59966y0FBQXpm2++0auvvipJCggI0Msvv6wNGzborbfe0pdffqm///3vkqT27dvrxRdfVEREhLW/xx9/3KNexhjdfvvtOnLkiFauXKklS5Zo+/bt6tmzp1u57du3a+HChfr000/16aefauXKlZo0aVIVtRaAyuByIYALSmRkpIKDg1WrVi3FxMRYy2fMmKGrr75aEyZMsJbNnj1b8fHx2rp1qy655BJJ0kUXXaTnnnvObZtnj+9q1qyZnn76aT300EP65z//qeDgYEVGRspms7nt71xLly7VTz/9pJ07dyo+Pl6S9M477+iyyy7TmjVrdM0110iSnE6n3nzzTdWuXVuS1LdvXy1btkzPPvts5RoGgNeRyQIASd99952WL1+u8PBw69WyZUtJRdkjl3bt2nl8dvny5erUqZPi4uJUu3Zt3X///Tp8+LBOnDhR5v1v3rxZ8fHxVoAlSa1bt1adOnW0efNma1lCQoIVYElSo0aNdODAgXIdKwDfIJMFACrKEN16662aPHmyx7pGjRpZ/w4LC3Nbt2vXLnXr1k0pKSl6+umnVa9ePX399dcaMGCA8vPzy7x/Y4xsNtvvLrfb7W7rbTabnE5nmfcDwHcIsgBccIKDg1VYWOi27Oqrr9b8+fOVkJCgoKCy/2pcu3atCgoK9PzzzysgoOjiwIcffvi7+ztX69attXv3bu3Zs8fKZm3atElZWVlq1apVmesD4PzB5UIAF5yEhAStXr1a6enpOnTokJxOpx555BEdOXJEvXv31rfffqsdO3YoNTVVDzzwQKkBUosWLVRQUKDp06drx44deueddzRz5kyP/R0/flzLli3ToUOHdPLkSY/t3HzzzWrTpo3uvfdeff/99/r22291//33Kzk5udhLlADOfwRZAC44jz/+uAIDA9W6dWvVr19fu3fvVmxsrL755hsVFhaqS5cuuvzyyzVkyBBFRkZaGaritG3bVtOmTdPkyZN1+eWX67333tPEiRPdyrRv314pKSnq2bOn6tev7zFwXiq67Ldw4ULVrVtXf/zjH3XzzTerefPmmjt3rtePH4Bv2Iwxxt+VAAAAqGnIZAEAAFQBgiwAAIAqQJAFAABQBQiyAAAAqgBBFgAAQBUgyAIAAKgCBFkAAABVgCALAACgChBkAQAAVAGCLAAAgCpAkAUAAFAFCLIAAACqwP8HAc73qgugzrQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of chains for parallel tempering:  13\n"
     ]
    }
   ],
   "source": [
    "ASIA_scores=ASIA_structure_MCMC[0]\n",
    "\n",
    "plt.plot(ASIA_scores[:100])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score traceplot ASIA during burn-in')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ASIA_scores[10000:])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score traceplot ASIA after burn-in')\n",
    "plt.show()\n",
    "\n",
    "print ('Optimal number of chains for parallel tempering: ', ASIA_structure_MCMC[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebb29f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGs are represented as adjacency matrices, therefore the tensor that contains all the DAGs sampled has shape: \n",
      "(n_nodes, n_nodes, n_DAGs sampled) \n",
      "\n",
      "In our case the shape is: (8, 8, 52000) \n",
      " \n",
      "\n",
      "Posterior probability of the edges using matrix notation (each entry represents the posterior probability of the edge going from node i (row index) to node j (column index)) \n",
      "\n",
      "[[0.   0.65 0.68 0.   0.01 0.09 0.   0.  ]\n",
      " [0.35 0.   0.   0.02 0.03 0.98 0.03 0.  ]\n",
      " [0.32 0.   0.   0.01 0.04 0.04 0.   1.  ]\n",
      " [0.   0.01 0.01 0.   0.42 0.14 0.01 0.  ]\n",
      " [0.01 0.02 0.02 0.44 0.   0.97 0.02 0.  ]\n",
      " [0.   0.02 0.   0.02 0.03 0.   0.99 1.  ]\n",
      " [0.   0.   0.   0.   0.   0.01 0.   0.  ]\n",
      " [0.   0.   0.   0.01 0.   0.   0.01 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "ASIA_DAGs=ASIA_structure_MCMC[1]\n",
    "\n",
    "print('DAGs are represented as adjacency matrices, therefore the tensor that contains all the DAGs sampled has shape: \\n(n_nodes, n_nodes, n_DAGs sampled) \\n')\n",
    "\n",
    "print('In our case the shape is:', np.shape(ASIA_DAGs),'\\n \\n')\n",
    "\n",
    "\n",
    "print('Posterior probability of the edges using matrix notation (each entry represents the posterior probability of the edge going from node i (row index) to node j (column index)) \\n')\n",
    "\n",
    "print(np.around(dag_mean_post(x=ASIA_DAGs,start=10000,end=52000),2))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
