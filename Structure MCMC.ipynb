{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af19e85e",
   "metadata": {},
   "source": [
    "# Structure MCMC with DEO parallel tempering scheme (and dynamic tuning of temperatures)\n",
    "### $MC^3$, $REV$ and $MBR$ moves implemented\n",
    "In this notebook you can find the functions for sampling DAGs using a simple structure MCMC or using a structure MCMC with a parallel tempering scheme implemented (DEO, SEO and single swap schemes).\n",
    "\n",
    "Two structure priors implemented: uniform and sparse.\n",
    "\n",
    "\n",
    "A practical example of sampling DAGs using DEO Structure MCMC can be found at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ec1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import splines   \n",
    "from scipy.special import logsumexp\n",
    "from math import comb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf47a6",
   "metadata": {
    "hideCode": false,
    "id": "8dcf47a6"
   },
   "source": [
    "### Loading the score file for the data  from .jkl format (BDeu or BGe score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684d8f74",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "684d8f74",
    "outputId": "3573ac84-dc6e-45a2-d913-892aa3a8627a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def cache_f (path,max_parents,n_nodes):\n",
    "\n",
    "    with open(path,'r') as file:\n",
    "        filedata = file.readlines()\n",
    "\n",
    "    n_parents_set=[]\n",
    "    cache ={}\n",
    "    \n",
    "    t=1\n",
    "    vertices=[]\n",
    "    for i in range (n_nodes):\n",
    "        line = filedata[t]\n",
    "        vertices.append(int(re.findall(r'\\d+', line)[0]))\n",
    "        t+=int(re.findall(r'\\d+', line)[1])+1\n",
    "\n",
    "    t=1\n",
    "    for i in vertices :\n",
    "        line = filedata[t]\n",
    "        now_n_parents_set =int(re.findall(r'\\d+', line)[1])\n",
    "\n",
    "        n_parents_set.append(now_n_parents_set)\n",
    "        now_dict= {}\n",
    "\n",
    "        for j in range(now_n_parents_set):\n",
    "            now_parents=()\n",
    "            for k in range (len(re.findall(r'\\d+', filedata[t+j+1]))-3):\n",
    "\n",
    "                now_parents= now_parents + (int(re.findall(r'\\d+', filedata[t+j+1])[k+3]),)\n",
    "\n",
    "            now_parents=tuple(sorted(now_parents))\n",
    "\n",
    "            now_dict[now_parents]=float(filedata[t+j+1].split(' ')[0])\n",
    "        cache[i]=now_dict\n",
    "        t=t+now_n_parents_set+1\n",
    "    return cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a3f48",
   "metadata": {
    "hideCode": false,
    "id": "483a3f48"
   },
   "source": [
    "### Generic functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481a610d",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": true,
    "id": "481a610d",
    "outputId": "a7a1cd98-3494-4d2e-9af7-d444b081e8e9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_dag(adjacency_matrix):\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "\n",
    "    colors = np.zeros(num_nodes, dtype=int)\n",
    "\n",
    "    def dfs(node):\n",
    "        nonlocal colors\n",
    "\n",
    "        colors[node] = 1  \n",
    "\n",
    "        for neighbor in np.where(adjacency_matrix[node] == 1)[0]:\n",
    "            if colors[neighbor] == 1:\n",
    "                return False  \n",
    "            elif colors[neighbor] == 0:\n",
    "                if not dfs(neighbor):\n",
    "                    return False\n",
    "\n",
    "        colors[node] = 2 \n",
    "        return True\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        if colors[node] == 0:\n",
    "            if not dfs(node):\n",
    "                return False  \n",
    "\n",
    "    return True \n",
    "\n",
    "def generate_random_dag_adjacency_matrix(num_nodes,max_parents):\n",
    "    if num_nodes <= 0:\n",
    "        raise ValueError(\"Number of nodes must be greater than 0.\")\n",
    "\n",
    "    nodes = np.random.permutation(num_nodes)\n",
    "\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "\n",
    "    for i in range(num_nodes - 1):\n",
    "        num_edges = np.random.randint(1, num_nodes - i)\n",
    "\n",
    "        target_nodes = np.random.choice(nodes[i+1:], size=num_edges, replace=False)\n",
    "\n",
    "        adjacency_matrix[nodes[i], target_nodes] = 1\n",
    "\n",
    "    new_dag= np.zeros((num_nodes,num_nodes),dtype=np.int8)\n",
    "    for i in range (num_nodes):\n",
    "        a=list(np.where(adjacency_matrix[:,i]==1)[0])\n",
    "        b=random.randint(0,max_parents)\n",
    "        c=random.sample(sorted(a), min(len(a),b))\n",
    "        for j in c:\n",
    "            new_dag[j,i]=1\n",
    "    return new_dag\n",
    "\n",
    "\n",
    "def score(dag):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "\n",
    "\n",
    "def bisection_at_x (f,a,b,x,max_iter=100,tol=1e-6):\n",
    "    for i in range (max_iter):\n",
    "        c = (a + b) / 2\n",
    "        if ((f(c) == x) or ((b - a) / 2 < tol)):\n",
    "            return(c)\n",
    "        if (f(c)< x):\n",
    "            a = c\n",
    "        else:\n",
    "            b = c\n",
    "    return (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1fe73",
   "metadata": {},
   "source": [
    "### Single $MC^3$ move (for structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c063b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mcmcmc (dag_now_p, loglik_now_p, prior_now_p, score_now_p,cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, max_parents,uniform\n",
    "\n",
    "    if beta==None:\n",
    "        beta=1\n",
    "    \n",
    "    dag0=np.copy(dag_now_p)\n",
    "    \n",
    "    condition=False\n",
    "    n_variables=len(dag_now_p[0])\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dag_now_p)\n",
    "        if (dag_now_p[u,v]==1) :\n",
    "            dag1[u,v]=0\n",
    "        elif (dag_now_p[v,u]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if (np.sum(dag1[:,v])>max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "            elif (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dag_now_p[u,v]==0 and dag_now_p[v,u]==0):\n",
    "            dag1[u,v]=1\n",
    "            if np.sum(dag1[:,v])>max_parents:\n",
    "                dag1[u,v]=0\n",
    "            elif (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "    prior_0=np.copy(prior_now_p)\n",
    "    loglik_0=np.copy(loglik_now_p)\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/comb((n_variables-1),np.sum(dag1[:,i])))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "\n",
    "    prior_1=np.log(prior_1)\n",
    "\n",
    "    \n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "\n",
    "        dag_now=np.copy(dag1)\n",
    "        prior_now = np.copy(prior_1)\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now= np.copy(prior_now+loglik_now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fb405",
   "metadata": {},
   "source": [
    "### Single $MC^3$ move (for PT Structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f06a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def pt_mcmcmc (dags_now_p, loglik_now_p, prior_now_p, beta,cache):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition=False\n",
    "    while(condition==False):\n",
    "        u=random.randint(0, n_variables-1)\n",
    "        v=list(range(n_variables))\n",
    "        v.remove(u)\n",
    "        v=random.choice(v)\n",
    "        dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "        if (dags_now_p[u,v,iterator]==1) :\n",
    "            dag1[u,v]=0\n",
    "\n",
    "        elif (dags_now_p[v,u,iterator]==1):\n",
    "            dag1[u,v]=1\n",
    "            dag1[v,u]=0\n",
    "            if  (np.sum(dag1[:,v])>max_parents):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "      \n",
    "            elif (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "                dag1[v,u]=1\n",
    "        elif (dags_now_p[u,v,iterator]==0 and dags_now_p[v,u,iterator]==0):\n",
    "            dag1[u,v]=1\n",
    "            if  np.sum(dag1[:,v])>max_parents:\n",
    "                dag1[u,v]=0\n",
    "\n",
    "            elif (is_dag(dag1)==False):\n",
    "                dag1[u,v]=0\n",
    "        condition=True\n",
    "\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "    prior_0=np.copy(prior_now_p[iterator])\n",
    "    loglik_0=np.copy(loglik_now_p[iterator])\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag1[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag1[:,i]==1)[0])]\n",
    "\n",
    "    prior_1=np.log(prior_1)\n",
    "\n",
    "    alpha= min(beta*(loglik_1-loglik_0)+prior_1-prior_0,0)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "\n",
    "        dags_now[:,:,iterator]=np.copy(dag1)\n",
    "        prior_now[iterator] = np.copy(prior_1)\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90bf5c1",
   "metadata": {},
   "source": [
    "### Single $REV$ move (for Structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9742c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def rev (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    " \n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "  \n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "     \n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "           \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "            \n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "     \n",
    "                dd_u=list(set(dd_u))\n",
    "    \n",
    "        d_u=set(d_u)\n",
    " \n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    " \n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "         \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "      \n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v=set(d_v)\n",
    "\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "            \n",
    "\n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i])\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "\n",
    "        \n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "\n",
    "        \n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            if uniform==False:\n",
    "                z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_j_cross.append(cache[v][i])\n",
    "                \n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "\n",
    "            \n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "            \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[v][i])\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    " \n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    " \n",
    "        d_u_plus=set(d_u_plus)\n",
    " \n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    " \n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            if uniform==False:\n",
    "                z_i_cross.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_i_cross.append(cache[u][i])\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        dag_now=np.copy(dag_tilde)\n",
    "        prior_now = np.copy(np.log(prior_1))\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=np.copy(loglik_now+prior_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211de3f5",
   "metadata": {},
   "source": [
    "### Single $REV$ move (for PT structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1bf29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_rev (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        ind=np.where(dag0==1)\n",
    "        indexes=[]\n",
    "    \n",
    "        for i in range (len(ind[0])):\n",
    "            indexes.append([ind[0][i],ind[1][i]])\n",
    "        \n",
    "\n",
    "        edge= random.sample(indexes,1)[0]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "  \n",
    "\n",
    "        pi_j=np.where(dag0[:,v])\n",
    "\n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        dag1[:,v]=np.zeros(n_variables)\n",
    "  \n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "    \n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "      \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "                  \n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "     \n",
    "                dd_u=list(set(dd_u))\n",
    "      \n",
    "        d_u=set(d_u)\n",
    "  \n",
    "\n",
    "        d_v=np.where(dag1[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v))\n",
    "  \n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "       \n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "           \n",
    "                    d_v=np.append(d_v,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "      \n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v=set(d_v)\n",
    "\n",
    "\n",
    "        pi_i_set=[item for item in cache[u] if v in item]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "    \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta)\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    " \n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "\n",
    "        d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "        dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_v)!=0:\n",
    "            child=dd_v.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_v_plus=np.append(d_v_plus,nephew)\n",
    "                    dd_v.append(nephew)\n",
    "\n",
    "                dd_v=list(set(dd_v))\n",
    "\n",
    "        d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "        pi_j_cross_set=[item for item in cache[v]]\n",
    "        for i in d_v_plus:\n",
    "            pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "            \n",
    "\n",
    "        z_j_cross=[]\n",
    "        for i in pi_j_cross_set:\n",
    "            if uniform==False:\n",
    "                z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_j_cross.append(cache[v][i]*beta)\n",
    "        Z=np.copy(z_j_cross)\n",
    "        z_j_cross=logsumexp(z_j_cross)\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        for i in pi_j_tilde:\n",
    "            dag_tilde[i,v]=1\n",
    "            \n",
    "\n",
    "        ''' backwards'''  \n",
    "            \n",
    "        pi_j_set_2=[item for item in cache[v] if u in item]\n",
    "        for i in d_v:\n",
    "            pi_j_set_2=[item for item in pi_j_set_2 if i not in item]   \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_j_set_2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[v][i]*beta)\n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        dag_tilde_cross=np.copy(dag1)\n",
    "        for i in pi_j:\n",
    "            dag_tilde_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        d_u_plus=np.where(dag_tilde_cross[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u_plus))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag_tilde_cross[child,:]==1)[0]:\n",
    "\n",
    "                    d_u_plus=np.append(d_u_plus,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u_plus=set(d_u_plus)\n",
    "\n",
    "        \n",
    "        \n",
    "        pi_i_cross_set=[item for item in cache[u]]\n",
    "        for i in d_u_plus:\n",
    "            pi_i_cross_set=[item for item in pi_i_cross_set if i not in item]\n",
    "\n",
    "        \n",
    "        z_i_cross=[]\n",
    "        for i in pi_i_cross_set:\n",
    "            if uniform==False:\n",
    "                z_i_cross.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_i_cross.append(cache[u][i]*beta)\n",
    "        z_i_cross=logsumexp(z_i_cross)\n",
    "        \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    alpha=min(0,np.log(np.sum(dag0))-np.log(np.sum(dag_tilde))+z_star_i_dot_j+z_j_cross-z_star_j_dot_i-z_i_cross)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        prior_1=1\n",
    "        loglik_1=0\n",
    "\n",
    "\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_tilde[:,i]))))\n",
    "            loglik_1+= cache[i][tuple(np.where(dag_tilde[:,i]==1)[0])]\n",
    "        \n",
    "        dags_now[:,:,iterator]=np.copy(dag_tilde)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ef235",
   "metadata": {},
   "source": [
    "### Single $MBR$ move (for structure MCMC without PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d36c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbr (dag_now_p, loglik_now_p, prior_now_p, score_now_p, cache, beta=1):\n",
    "    global score_now, dag_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, steps, rev_post, rev_tot,rand_steps,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dag_now_p)\n",
    "    dag0=np.copy(dag_now_p)\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        \n",
    "        u=random.randint(0,n_variables-1)\n",
    " \n",
    "        \n",
    "        pi_i=np.where(dag0[:,u]==1)[0]\n",
    "\n",
    "        \n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u=np.where(dag1[u,:]==1)[0]        \n",
    "        for i in c_u:\n",
    "            dag1[:,i]=np.zeros(n_variables)\n",
    "            dag1[u,i]=1\n",
    "        \n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u=set(d_u)\n",
    "\n",
    "        pi_i_set2=[item for item in cache[u]]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]\n",
    "\n",
    "        pi_i_set=pi_i_set2.copy()\n",
    "\n",
    "        for i in pi_i:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "\n",
    "        \n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i])\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        \n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "        \n",
    "        ''' until here the new parents set of u is sampled'''\n",
    "        z_c=0\n",
    "        c_u=list(c_u)\n",
    "\n",
    "        random.shuffle(c_u)\n",
    "        c_u=tuple(c_u)\n",
    "\n",
    "        for v in c_u:\n",
    "\n",
    "            d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "                \n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i])\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c+=z_j_cross\n",
    "\n",
    "            \n",
    "            \n",
    "            log_probs = Z\n",
    "            num_categories = len(Z)\n",
    "            gumbels = np.random.gumbel(size=num_categories)\n",
    "            sample = np.argmax(log_probs + gumbels)\n",
    "            pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "            for i in pi_j_tilde:\n",
    "                dag_cross[i,v]=1\n",
    "\n",
    "        ''' backwards'''  \n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        dag_tilde[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u_b=np.where(dag_tilde[u,:]==1)[0]        \n",
    "        for i in c_u_b:\n",
    "            dag_tilde[:,i]=np.zeros(n_variables)\n",
    "            dag_tilde[u,i]=1\n",
    "\n",
    "        for i in pi_i_tilde:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]   \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_i_set2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[u][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[u][i])\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        for i in pi_i:\n",
    "            dag_tilde[i,u]=1\n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "        z_c_b=0\n",
    "        c_u_b=list(c_u_b)\n",
    "\n",
    "        random.shuffle(c_u_b)\n",
    "        c_u_b=tuple(c_u_b)\n",
    "        for v in c_u_b:\n",
    "            d_v_plus=np.where(dag_tilde[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "  \n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_tilde[child,:]==1)[0]:\n",
    "          \n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "        \n",
    "                    dd_v=list(set(dd_v))\n",
    "    \n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i])\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c_b+=np.copy(z_j_cross)\n",
    "\n",
    "            dag_tilde[:,v]=np.copy(dag0[:,v])\n",
    "    \n",
    "\n",
    "        condition= True\n",
    "\n",
    "    prior_1=1\n",
    "    loglik_1=0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_cross[:,i]))))\n",
    "        loglik_1+= cache[i][tuple(np.where(dag_cross[:,i]==1)[0])]\n",
    "\n",
    "    alpha=min(0,z_star_i_dot_j+z_c-z_star_j_dot_i-z_c_b)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        dag_now=np.copy(dag_cross)\n",
    "        prior_now = np.copy(np.log(prior_1))\n",
    "        loglik_now= np.copy(loglik_1)\n",
    "        score_now=np.copy(loglik_now+prior_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d5cbe",
   "metadata": {},
   "source": [
    "### Single $MBR$ move (for PT structure MCMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18ca62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_mbr (dags_now_p, loglik_now_p, prior_now_p, beta, cache):\n",
    "    global  dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains,uniform\n",
    "\n",
    "    condition= False\n",
    "    dag1=np.copy(dags_now_p[:,:,iterator])\n",
    "    dag0=np.copy(dags_now_p[:,:,iterator])\n",
    "\n",
    "    if np.sum(dag0)==0:\n",
    "        return None\n",
    "\n",
    "    while(condition==False):\n",
    "        \n",
    "        u=random.randint(0,n_variables-1)\n",
    "\n",
    "        \n",
    "        pi_i=np.where(dag0[:,u]==1)[0]\n",
    "\n",
    "        \n",
    "        dag1[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u=np.where(dag1[u,:]==1)[0]        \n",
    "        for i in c_u:\n",
    "            dag1[:,i]=np.zeros(n_variables)\n",
    "            dag1[u,i]=1\n",
    "\n",
    "        d_u=np.where(dag1[u,:]==1)[0]\n",
    "        dd_u=list(np.copy(d_u))\n",
    "\n",
    "        visited=[]\n",
    "        while len(dd_u)!=0:\n",
    "            child=dd_u.pop()\n",
    "\n",
    "            if child not in visited:\n",
    "                visited.append(child)\n",
    "                for nephew in np.where(dag1[child,:]==1)[0]:\n",
    "\n",
    "                    d_u=np.append(d_u,nephew)\n",
    "                    dd_u.append(nephew)\n",
    "\n",
    "                dd_u=list(set(dd_u))\n",
    "\n",
    "        d_u=set(d_u)\n",
    "\n",
    "        pi_i_set2=[item for item in cache[u]]\n",
    "\n",
    "        for i in d_u:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]\n",
    "\n",
    "        pi_i_set=pi_i_set2.copy()\n",
    "\n",
    "        for i in pi_i:\n",
    "            pi_i_set=[item for item in pi_i_set if i not in item]\n",
    "\n",
    "        z_star_i_dot_j=[]\n",
    "        for i in pi_i_set:\n",
    "\n",
    "            if uniform==False:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_i_dot_j.append(cache[u][i]*beta)\n",
    "\n",
    "        Z=np.copy(z_star_i_dot_j)\n",
    "\n",
    "        z_star_i_dot_j=logsumexp(z_star_i_dot_j)\n",
    "\n",
    "        \n",
    "        \n",
    "        log_probs = Z\n",
    "        num_categories = len(Z)\n",
    "        gumbels = np.random.gumbel(size=num_categories)\n",
    "\n",
    "        sample = np.argmax(log_probs + gumbels)\n",
    "        pi_i_tilde=pi_i_set[sample]\n",
    "        \n",
    "\n",
    "        dag_cross=np.copy(dag1)\n",
    "        for i in pi_i_tilde:\n",
    "            dag_cross[i,u]=1\n",
    "\n",
    "        \n",
    "        ''' until here the new parents set of u is sampled'''\n",
    "        z_c=0\n",
    "        c_u=list(c_u)\n",
    "\n",
    "        random.shuffle(c_u)\n",
    "        c_u=tuple(c_u)\n",
    "\n",
    "        for v in c_u:\n",
    "\n",
    "            d_v_plus=np.where(dag_cross[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    "\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_cross[child,:]==1)[0]:\n",
    "\n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "            \n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            \n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i]*beta)\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c+=z_j_cross\n",
    "\n",
    "            \n",
    "            log_probs = Z\n",
    "            num_categories = len(Z)\n",
    "            gumbels = np.random.gumbel(size=num_categories)\n",
    "            sample = np.argmax(log_probs + gumbels)\n",
    "            pi_j_tilde=pi_j_cross_set[sample]\n",
    "\n",
    "        \n",
    "            for i in pi_j_tilde:\n",
    "                dag_cross[i,v]=1\n",
    "\n",
    "            \n",
    "        ''' backwards'''  \n",
    "        \n",
    "        dag_tilde=np.copy(dag_cross)\n",
    "        \n",
    "        dag_tilde[:,u]=np.zeros(n_variables)\n",
    "        \n",
    "        c_u_b=np.where(dag_tilde[u,:]==1)[0]        \n",
    "        for i in c_u_b:\n",
    "            dag_tilde[:,i]=np.zeros(n_variables)\n",
    "            dag_tilde[u,i]=1\n",
    "        \n",
    "\n",
    "        for i in pi_i_tilde:\n",
    "            pi_i_set2=[item for item in pi_i_set2 if i not in item]   \n",
    "            \n",
    "\n",
    "        \n",
    "        z_star_j_dot_i=[]\n",
    "        for i in pi_i_set2:\n",
    "            if uniform==False:\n",
    "                z_star_j_dot_i.append(cache[u][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "            else:\n",
    "                z_star_j_dot_i.append(cache[u][i]*beta)\n",
    "                \n",
    "        z_star_j_dot_i=logsumexp(z_star_j_dot_i)\n",
    "        \n",
    "        for i in pi_i:\n",
    "            dag_tilde[i,u]=1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        z_c_b=0\n",
    "        c_u_b=list(c_u_b)\n",
    "\n",
    "        random.shuffle(c_u_b)\n",
    "        c_u_b=tuple(c_u_b)\n",
    "        for v in c_u_b:\n",
    "            d_v_plus=np.where(dag_tilde[v,:]==1)[0]\n",
    "            dd_v=list(np.copy(d_v_plus))\n",
    "\n",
    "            visited=[]\n",
    "            while len(dd_v)!=0:\n",
    "                child=dd_v.pop()\n",
    " \n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    for nephew in np.where(dag_tilde[child,:]==1)[0]:\n",
    "   \n",
    "                        d_v_plus=np.append(d_v_plus,nephew)\n",
    "                        dd_v.append(nephew)\n",
    "\n",
    "                    dd_v=list(set(dd_v))\n",
    "\n",
    "            d_v_plus=set(d_v_plus)\n",
    "\n",
    "\n",
    "            pi_j_cross_set=[item for item in cache[v] if u in item]\n",
    "            for i in d_v_plus:\n",
    "                pi_j_cross_set=[item for item in pi_j_cross_set if i not in item]\n",
    "\n",
    "            z_j_cross=[]\n",
    "            for i in pi_j_cross_set:\n",
    "                if uniform==False:\n",
    "                    z_j_cross.append(cache[v][i]*beta+np.log(1/math.comb((n_variables-1),int(len(i)))))\n",
    "                else:\n",
    "                    z_j_cross.append(cache[v][i]*beta)\n",
    "                    \n",
    "            Z=np.copy(z_j_cross)\n",
    "            z_j_cross=logsumexp(z_j_cross)\n",
    "            z_c_b+=np.copy(z_j_cross)\n",
    "\n",
    "            dag_tilde[:,v]=np.copy(dag0[:,v])\n",
    "    \n",
    "\n",
    "        condition= True\n",
    "    \n",
    "\n",
    "    \n",
    "    alpha=min(0,z_star_i_dot_j+z_c-z_star_j_dot_i-z_c_b)\n",
    "\n",
    "    rand=random.random()\n",
    "\n",
    "    if rand < np.exp(alpha):\n",
    "\n",
    "        prior_1=1\n",
    "        loglik_1=0\n",
    "\n",
    "\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_1= prior_1*(1/math.comb((n_variables-1),int(np.sum(dag_cross[:,i]))))\n",
    "            loglik_1+= cache[i][tuple(np.where(dag_cross[:,i]==1)[0])]\n",
    "        \n",
    "        dags_now[:,:,iterator]=np.copy(dag_cross)\n",
    "        prior_now[iterator]= np.copy(np.log(prior_1))\n",
    "        loglik_now[iterator]= np.copy(loglik_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8e087",
   "metadata": {},
   "source": [
    "### Structure MCMC without PT (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d83fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, prob_rev=.7, prob_mbr=.2,seed=None,uniform_p=False):\n",
    "    global score_now,n_variables, dag_now, loglik_now, prior_now, tot_swaps, max_parents,uniform\n",
    "\n",
    "    uniform=uniform_p\n",
    "    n_variables=int(n_variables_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    dag_now= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    dags =np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    scores=np.zeros(n_iter)\n",
    "\n",
    "    prior_now=1\n",
    "    loglik_now=0\n",
    "\n",
    "    for i in range(n_variables):\n",
    "        if uniform==False:\n",
    "            prior_now= prior_now*(1/comb((n_variables-1),np.sum(dag_now[:,i])))\n",
    "        loglik_now+= cache[i][tuple(np.where(dag_now[:,i]==1)[0])]\n",
    "    \n",
    "    prior_now=np.log(prior_now)\n",
    "    score_now=loglik_now+prior_now\n",
    "\n",
    "    dags[:,:,0]=dag_now\n",
    "    scores[0]=score_now\n",
    "    for i in range(n_iter-1):\n",
    "        r_num=random.random() \n",
    "        if r_num> prob_rev+prob_mbr:\n",
    "            mcmcmc(dag_now, loglik_now, prior_now, score_now, cache,1)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "        elif r_num<prob_rev:\n",
    "\n",
    "            rev(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "        else:\n",
    "\n",
    "            mbr(dag_now, loglik_now, prior_now, score_now, cache)\n",
    "            dags[:,:,i+1]=np.copy(dag_now)\n",
    "            scores[i+1]=np.copy(score_now)\n",
    "\n",
    "    return scores,dags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa380a6c",
   "metadata": {},
   "source": [
    "### DEO structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca0b6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            \n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "      \n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "            if complete==True:\n",
    "                beta_array_train.append(list(betas))\n",
    "            \n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "        \n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "     \n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "\n",
    "                if (((j%2+k%2)==0) or ((j%2+k%2)==2)):\n",
    "\n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r[1:],R[1:],betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f8276",
   "metadata": {},
   "source": [
    "### Random single swap structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ac37c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "        \n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            \n",
    "            index=random.randint(0,n_chains-1)\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if j==index:\n",
    "\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "\n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "            if complete==True:\n",
    "                beta_array_train.append(list(betas))\n",
    "            \n",
    "\n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "\n",
    "        index=random.randint(0,n_chains-1)\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "                if j==index:\n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "    \n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r[1:],R[1:],betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaab703",
   "metadata": {},
   "source": [
    "### SEO structure MCMC (main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11dbc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seo_structure_mcmc (n_variables_p, max_parents_p, n_iter, cache, training_iter, n_chains_p, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False):\n",
    "    global dags_now, loglik_now, prior_now, iterator, n_variables, max_parents, n_chains, uniform\n",
    "\n",
    "    random.seed(seed)\n",
    "    n_variables=int(n_variables_p)\n",
    "    n_chains=int(n_chains_p)\n",
    "    max_parents=int(max_parents_p)\n",
    "    np.random.seed(seed)\n",
    "    uniform=uniform_p\n",
    "\n",
    "    chain_rej=1/(n_chains-1)\n",
    "    betas=np.zeros(n_chains)\n",
    "    betas[n_chains-1]=1\n",
    "    for i in range (n_chains-1):\n",
    "        betas[i]=chain_rej*i\n",
    "        \n",
    "    if geometric==True:\n",
    "        bet=list(np.arange(1,n_chains))\n",
    "        bet.reverse()\n",
    "        bet=np.array(bet)\n",
    "        betas[0]=0\n",
    "        betas[1:]=1/bet\n",
    "\n",
    "    training_steps= math.log2(training_iter)\n",
    "    training_list= []\n",
    "    training_counter=0\n",
    "    for i in range (int(training_steps-2)):\n",
    "        training_list.append(2**(i+1))\n",
    "        training_counter+=2**(i+1)\n",
    "    training_list.append(training_iter-training_counter)\n",
    "\n",
    "    dags_now= np.zeros((n_variables,n_variables,n_chains),dtype=np.int8)\n",
    "    loglik_now=np.zeros((n_chains))\n",
    "    prior_now= np.zeros((n_chains))\n",
    "    post_scores=  np.zeros(training_iter)\n",
    "    post_dags= np.zeros((n_variables,n_variables,training_iter),dtype=np.int8)\n",
    "    indexes_matrix_train=np.zeros((n_chains,training_iter))\n",
    "    indexes_matrix_train[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    for i in range(n_chains):\n",
    "        dags_now[:,:,i]= generate_random_dag_adjacency_matrix(n_variables,max_parents)\n",
    "\n",
    "    for j in range (n_chains):\n",
    "        prior_t=1\n",
    "        loglik_t=0\n",
    "        for i in range(n_variables):\n",
    "            if uniform==False:\n",
    "                prior_t= prior_t*(1/math.comb((n_variables-1),int(np.sum(dags_now[:,i,j]))))\n",
    "            loglik_t+= cache[i][tuple(np.where(dags_now[:,i,j]==1)[0])]\n",
    "        prior_t=np.log(prior_t)\n",
    "        prior_now[j]= prior_t\n",
    "        loglik_now[j]= loglik_t\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    if complete==True:\n",
    "        beta_array_train=[]\n",
    "        beta_array_train.append(list(betas))  \n",
    "    \n",
    "\n",
    "    for i in training_list:\n",
    "        r=np.zeros(n_chains)\n",
    "        for k in range(i):\n",
    "            K=random.random()\n",
    "            if K<.5:\n",
    "                K=1\n",
    "            else:\n",
    "                K=2\n",
    "            for j in range (n_chains):\n",
    "                iterator=j\n",
    "                rand=random.random()\n",
    "                if rand > prob_rev+prob_mbr:\n",
    "                    pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                elif rand<prob_rev:\n",
    "                    pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "                else:\n",
    "                    pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            for j in range (n_chains-1):\n",
    "                alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "                if alpha== np.nan:\n",
    "                    alpha=0\n",
    "                #print(alpha,j)\n",
    "                r[j+1]+=(1-alpha)\n",
    "                r_number=random.random()\n",
    "                if r_number< alpha :\n",
    "                    if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "                        #print('swap',j)\n",
    "                        if complete==True:\n",
    "                            ind1=np.copy(indexes_matrix_train[j,counter])\n",
    "                            ind2=np.copy(indexes_matrix_train[j+1,counter])\n",
    "                            indexes_matrix_train[j,counter]=ind2\n",
    "                            indexes_matrix_train[j+1,counter]=ind1\n",
    "                        d1=np.copy(dags_now[:,:,j])\n",
    "                        d2=np.copy(dags_now[:,:,j+1])\n",
    "                        dags_now[:,:,j+1]=d1\n",
    "                        dags_now[:,:,j]=d2\n",
    "                        l1=np.copy(loglik_now[j])\n",
    "                        l2=np.copy(loglik_now[j+1])\n",
    "                        loglik_now[j+1]=l1\n",
    "                        loglik_now[j]=l2\n",
    "                        p1=np.copy(prior_now[j])\n",
    "                        p2=np.copy(prior_now[j+1])\n",
    "                        prior_now[j+1]=p1\n",
    "                        prior_now[j]=p2\n",
    "\n",
    "\n",
    "            post_dags[:,:,counter]=np.copy(dags_now[:,:,n_chains-1])\n",
    "            post_scores[counter]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "            counter+=1\n",
    "            if complete==True:\n",
    "                if counter <training_iter:\n",
    "                    indexes_matrix_train[:,counter]=np.copy(indexes_matrix_train[:,counter-1])\n",
    "\n",
    "        if geometric==False:\n",
    "            r=r/(k+1)\n",
    "            arr_lambda= np.cumsum(r)\n",
    "\n",
    "            lambda_1=arr_lambda[-1]\n",
    "            r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "            pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "            X=np.arange(0,1,.001)\n",
    "    \n",
    "            for j in range (n_chains):\n",
    "                betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "\n",
    "            betas[0]=0\n",
    "            betas[n_chains-1]=1\n",
    "\n",
    "        if complete==True:\n",
    "            beta_array_train.append(list(betas))\n",
    "            \n",
    "    \n",
    "    if geometric==False:\n",
    "        n_chains= int(2*lambda_1)\n",
    "        r_star= lambda_1/(n_chains-1)\n",
    "        betas= np.zeros(n_chains)\n",
    "        for j in range (n_chains):\n",
    "            betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "        betas[n_chains-1]=1\n",
    "        betas[0]=0\n",
    "    if complete==True:\n",
    "        beta_array_final=[]\n",
    "        beta_array_final.append(list(betas))\n",
    "        \n",
    "\n",
    "    final_scores=  np.zeros((n_chains, n_iter))\n",
    "    final_dags= np.zeros((n_variables,n_variables, n_chains, n_iter),dtype=np.int8)\n",
    "    final_post_scores= np.zeros(n_iter)\n",
    "    final_post_dags= np.zeros((n_variables, n_variables, n_iter),dtype=np.int8)\n",
    "    indexes_matrix=np.zeros((n_chains,n_iter))\n",
    "    indexes_matrix[:,0]=np.array(list(range(n_chains)))\n",
    "\n",
    "\n",
    "    dags_now= dags_now[:,:,-n_chains:]\n",
    "    loglik_now=loglik_now[-n_chains:]\n",
    "    prior_now= prior_now[-n_chains:]\n",
    "\n",
    "\n",
    "    counter=0\n",
    "    r=np.zeros(n_chains)\n",
    "    R=np.zeros(n_chains)\n",
    "    for k in range(n_iter):\n",
    "        K=random.random()\n",
    "        if K<.5:\n",
    "            K=1\n",
    "        else:\n",
    "            K=2\n",
    "        for j in range (n_chains):\n",
    "            iterator=j\n",
    "            rand=random.random()\n",
    "            if rand > prob_rev+prob_mbr:\n",
    "                pt_mcmcmc (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "            elif rand<prob_rev:\n",
    "                pt_rev (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "            else:\n",
    "                pt_mbr (dags_now, loglik_now, prior_now, betas[j],cache)\n",
    "\n",
    "        \n",
    "\n",
    "        for j in range (n_chains-1):\n",
    "            alpha= np.exp(min((loglik_now[j]-loglik_now[j+1])*(betas[j+1]-betas[j]),0))\n",
    "            if alpha== np.nan:\n",
    "                alpha=0\n",
    "\n",
    "            r[j+1]+=(1-alpha)\n",
    "            R[j+1]+=(1-alpha)\n",
    "            r_number=random.random()\n",
    "            if r_number< alpha :\n",
    "\n",
    "                if (((j%2+K%2)==0) or ((j%2+K%2)==2)):\n",
    "          \n",
    "                    if complete==True:\n",
    "                        ind1=np.copy(indexes_matrix[j,k])\n",
    "                        ind2=np.copy(indexes_matrix[j+1,k])\n",
    "                        indexes_matrix[j,k]=ind2\n",
    "                        indexes_matrix[j+1,k]=ind1\n",
    "                    d1=np.copy(dags_now[:,:,j])\n",
    "                    d2=np.copy(dags_now[:,:,j+1])\n",
    "                    dags_now[:,:,j+1]=d1\n",
    "                    dags_now[:,:,j]=d2\n",
    "                    l1=np.copy(loglik_now[j])\n",
    "                    l2=np.copy(loglik_now[j+1])\n",
    "                    loglik_now[j+1]=l1\n",
    "                    loglik_now[j]=l2\n",
    "                    p1=np.copy(prior_now[j])\n",
    "                    p2=np.copy(prior_now[j+1])\n",
    "                    prior_now[j+1]=p1\n",
    "                    prior_now[j]=p2\n",
    "\n",
    "        \n",
    "        if complete==True:\n",
    "            \n",
    "            for j in range (n_chains):\n",
    "\n",
    "                final_scores[j,k]=loglik_now[j]+prior_now[j]\n",
    "                final_dags[:,:,j,k]=dags_now[:,:,j]\n",
    "                \n",
    "        final_post_dags[:,:,k]=np.copy(dags_now[:,:,n_chains-1])\n",
    "        final_post_scores[k]=np.copy(loglik_now[n_chains-1])+np.copy(prior_now[n_chains-1])\n",
    "        if complete==True:\n",
    "            if k <(n_iter-1):\n",
    "                indexes_matrix[:,k+1]=np.copy(indexes_matrix[:,k])\n",
    "\n",
    "        counter+=1\n",
    "        \n",
    "        if ((dynamic==True or (k//step_tune)<n_tune) and geometric==False):\n",
    "            if k%step_tune==0:\n",
    "                r=r/(counter)\n",
    "                arr_lambda= np.cumsum(r)\n",
    "                lambda_1=arr_lambda[-1]\n",
    "                r_star=lambda_1/(n_chains-1)\n",
    "    \n",
    "                pchip=scipy.interpolate.PchipInterpolator(betas, arr_lambda, axis=0, extrapolate=None)\n",
    "                X=np.arange(0,1,.001)\n",
    "\n",
    "                for j in range (n_chains):\n",
    "                    betas[j]=bisection_at_x(pchip,0,1,r_star*j)\n",
    "                betas[0]=0\n",
    "                betas[n_chains-1]=1\n",
    "    \n",
    "                r=np.zeros(n_chains)\n",
    "                counter=0\n",
    "                \n",
    "                if complete==True:\n",
    "                    beta_array_final.append(list(betas))\n",
    "\n",
    "\n",
    "    \n",
    "    r=r/(counter)\n",
    "    R=R/(n_iter)\n",
    "    print(R[1:],'rejection ratio among chains')\n",
    "    print(betas,'betas')\n",
    "\n",
    "    \n",
    "    tot_post=np.concatenate([post_scores,final_post_scores])\n",
    "    if complete==False:\n",
    "        beta_array_final=0\n",
    "        beta_array_train=0\n",
    "    else:\n",
    "        beta_array_final=np.array(beta_array_final)\n",
    "        beta_array_train=np.array(beta_array_train)\n",
    "    \n",
    "    final_post_dags=np.concatenate([post_dags,final_post_dags],axis=2)\n",
    "    \n",
    "    if complete==False:\n",
    "        return tot_post, final_post_dags, n_chains, r[1:],R[1:],betas\n",
    "    else:\n",
    "        return tot_post, final_post_dags, indexes_matrix, n_chains, r[1:],R[1:],betas,beta_array_train,beta_array_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5e196",
   "metadata": {},
   "source": [
    "### Diagnostic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ef8f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restarts(chain):\n",
    "    rest=0\n",
    "    ground=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        ground[int(chain[2][0,i])]=1\n",
    "        if ground[int(chain[2][chain[3]-1,i])]==1:\n",
    "            ground[int(chain[2][chain[3]-1,i])]=0\n",
    "            rest+=1\n",
    "    return rest\n",
    "\n",
    "def plot_swaps (chain):\n",
    "    a=[]\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        a.append(int(np.where(chain[2][:,i]==2)[0]))\n",
    "    plt.plot(a)\n",
    "    plt.show()\n",
    "\n",
    "def score(dag,cache):\n",
    "    prior=1\n",
    "    loglik=0\n",
    "    n_variables=len(dag)\n",
    "    for i in range(n_variables):\n",
    "        prior= prior*(1/math.comb((n_variables-1),int(np.sum(dag[:,i]))))\n",
    "        loglik+= cache[i][tuple(np.where(dag[:,i]==1)[0])]\n",
    "    return loglik+ np.log(prior)\n",
    "\n",
    "def mixing_ratio(chain):\n",
    "    ratio_post=0\n",
    "    ratio=np.zeros(chain[3])\n",
    "    for i in range (len(chain[2][0,:])):\n",
    "        for j in range(chain[3]):\n",
    "            ratio[int(chain[2][j,i])]+=(chain[3]-1-j)/(chain[3])\n",
    "        ratio_post+= ratio[int(chain[2][chain[3]-1,i])]\n",
    "        ratio[int(chain[2][chain[3]-1,i])]=0\n",
    "    return ratio_post/len(chain[2][0,:])\n",
    "\n",
    "def dag_mean_post (x,start,end):\n",
    "    dim=len(x[:,0,0])\n",
    "    dag=np.zeros((dim,dim))\n",
    "    for i in range(start,end):\n",
    "        dag += x[:,:,i]\n",
    "    return dag/(end-start) \n",
    "\n",
    "def l1_loss(x,c,ref):\n",
    "    \n",
    "    dmp=[]\n",
    "    for i in x:\n",
    "        dmp.append(dag_mean_post(c[1],x[0],i))\n",
    "\n",
    "    u=[]\n",
    "    for i in dmp:\n",
    "        u.append(np.sum(np.abs(i-ref)))\n",
    "    return u\n",
    "\n",
    "def max_loss(x,c,ref):\n",
    "    \n",
    "    dmp=[]\n",
    "    for i in x:\n",
    "        dmp.append(dag_mean_post(c[1],x[0],i))\n",
    "\n",
    "    u=[]\n",
    "    for i in dmp:\n",
    "        u.append(np.max(np.abs(i-ref)))\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1c33a",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e4a8223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59683768 0.54679182 0.48908342 0.49555525 0.48631496 0.48482636\n",
      " 0.48194264 0.4753517  0.47489604 0.47829866 0.4774215  0.5342693 ] rejection ratio among chains\n",
      "[0.00000000e+00 5.80787659e-04 1.29604340e-03 2.73799896e-03\n",
      " 5.43117523e-03 9.60254669e-03 1.76420212e-02 4.16841507e-02\n",
      " 1.08778954e-01 2.18211174e-01 3.69664192e-01 6.08809471e-01\n",
      " 1.00000000e+00] betas\n"
     ]
    }
   ],
   "source": [
    "ASIA_cache=cache_f('data/asia-10000-3p.jkl',3,8)\n",
    "\n",
    "ASIA_structure_MCMC=deo_structure_mcmc (n_variables_p=8, max_parents_p=3, n_iter=50000, cache=ASIA_cache, training_iter=2000, n_chains_p=30, prob_rev=.7, prob_mbr=.2,seed=None, dynamic=True, geometric=False,complete=False,step_tune=3000,n_tune=8,uniform_p=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f655d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of chains for parallel tempering:  13\n"
     ]
    }
   ],
   "source": [
    "ASIA_scores=ASIA_structure_MCMC[0]\n",
    "\n",
    "plt.plot(ASIA_scores[:100])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score traceplot ASIA during burn-in')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ASIA_scores[10000:])\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score traceplot ASIA after burn-in')\n",
    "plt.show()\n",
    "\n",
    "print ('Optimal number of chains for parallel tempering: ', ASIA_structure_MCMC[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebb29f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGs are represented as adjacency matrices, therefore the tensor that contains all the DAGs sampled has shape: \n",
      "(n_nodes, n_nodes, n_DAGs sampled) \n",
      "\n",
      "In our case the shape is: (8, 8, 52000) \n",
      " \n",
      "\n",
      "Posterior probability of the edges using matrix notation (each entry represents the posterior probability of the edge going from node i (row index) to node j (column index)) \n",
      "\n",
      "[[0.   0.66 0.66 0.   0.01 0.08 0.   0.  ]\n",
      " [0.34 0.   0.   0.02 0.04 0.98 0.02 0.  ]\n",
      " [0.34 0.   0.   0.   0.03 0.04 0.   1.  ]\n",
      " [0.   0.02 0.01 0.   0.4  0.13 0.01 0.  ]\n",
      " [0.01 0.02 0.02 0.45 0.   0.96 0.02 0.  ]\n",
      " [0.   0.02 0.   0.02 0.04 0.   0.98 1.  ]\n",
      " [0.   0.   0.   0.   0.   0.01 0.   0.  ]\n",
      " [0.   0.   0.   0.01 0.   0.   0.01 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "ASIA_DAGs=ASIA_structure_MCMC[1]\n",
    "\n",
    "print('DAGs are represented as adjacency matrices, therefore the tensor that contains all the DAGs sampled has shape: \\n(n_nodes, n_nodes, n_DAGs sampled) \\n')\n",
    "\n",
    "print('In our case the shape is:', np.shape(ASIA_DAGs),'\\n \\n')\n",
    "\n",
    "\n",
    "print('Posterior probability of the edges using matrix notation (each entry represents the posterior probability of the edge going from node i (row index) to node j (column index)) \\n')\n",
    "\n",
    "print(np.around(dag_mean_post(x=ASIA_DAGs,start=10000,end=52000),2))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "differentiable-dag-sampling",
   "language": "python",
   "name": "differentiable-dag-sampling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
